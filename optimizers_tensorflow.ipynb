{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4923e798-ffe9-4348-809a-af9235e749a0",
   "metadata": {},
   "source": [
    "# Optimizers Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d173b-379d-4a94-a57e-a3d256a59950",
   "metadata": {},
   "source": [
    "# Simple Demo 1D SGD with animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f181f-29b1-46a6-b4de-39cf4ccc1854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "var = tf.Variable(5.0)\n",
    "loss = lambda: (var ** 2)/2.0         # d(loss)/d(var1) = var1\n",
    "tt = []\n",
    "for j in range(100):\n",
    "    step_count = opt.minimize(loss, [var]).numpy()\n",
    "    tt.append(var.numpy())\n",
    "\n",
    "\n",
    "lossf = lambda x: (x ** 2)/2.0         # d(loss)/d(var1) = var1\n",
    "\n",
    "x=list(np.linspace(-6, 6.0, 100))\n",
    "y = []\n",
    "for xx in x:\n",
    "    y.append(lossf(xx))\n",
    "\n",
    "ll = []\n",
    "for t in tt:\n",
    "    ll.append(lossf(t))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.scatter(tt, ll)\n",
    "\n",
    "xx = []\n",
    "x_sgd = tf.Variable(5.0)\n",
    "def animate_optimizer(frame, opt, loss, lossf, x_sgd, xx, p2, p3):\n",
    "    step_count = opt.minimize(loss, var_list=[x_sgd]).numpy()\n",
    "    p3.set_data(x_sgd.numpy(), lossf(x_sgd.numpy()))\n",
    "    xx.append(x_sgd.numpy() )\n",
    "    loss_y = [lossf(xt) for xt in xx]\n",
    "    p2.set_data(xx, loss_y)\n",
    "    return p2, p3, x_sgd\n",
    "\n",
    "\n",
    "plt.clf\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel('w1')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Gradient Descent')\n",
    "\n",
    "## 1d 1single weight loss plot\n",
    "\n",
    "x_sgd = tf.Variable(5.0)\n",
    "p1, = ax.plot([x_sgd], [lossf(x_sgd)], 'k')\n",
    "p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "p2, = ax.plot([], [],  'r.', marker='.', alpha=.5)\n",
    "\n",
    "p3, = ax.plot([], [],  'r.', marker='.', alpha=.5, ms=10)\n",
    "max_iter = 100\n",
    "loss = lambda: (x_sgd ** 2)/2.0      \n",
    "\n",
    "anim2 = animation.FuncAnimation(fig, animate_optimizer, \n",
    "                                frames=range(0, max_iter),  fargs = (opt, loss, lossf, x_sgd, xx, p2, p3), blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "filename = '/home/ronen/Downloads/sgd_1d_intro.gif'\n",
    "anim2\n",
    "anim2.save(filename, dpi=80, writer='imagemagick', fps=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce34ff-9dc0-4d5c-8cad-6ee6934d4b75",
   "metadata": {},
   "source": [
    "# Simple Demo  SGD with 2D Contour animation animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ac4cb-aa5b-4bba-ae87-660ddf39eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "var = tf.Variable(5.0)\n",
    "loss = lambda: (var ** 2)/2.0         # d(loss)/d(var1) = var1\n",
    "\n",
    "\n",
    "#### Now contour 2 weights:\n",
    "\n",
    "\n",
    "def plot_contour(loss_with_args):\n",
    "    x = np.linspace(-5.5, 5.5, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    return fig,ax\n",
    "\n",
    "def animate_optimizer(frame, opt, loss_func, xxx, yyy, xx, yy, p2, p3, p4):\n",
    "    step_count = opt.minimize(loss_func, var_list=[xxx, yyy]).numpy()\n",
    " \n",
    "    p3.set_data(xxx.numpy(), yyy.numpy())\n",
    "    xx.append(xxx.numpy())\n",
    "    yy.append(yyy.numpy())\n",
    "    p2.set_data(xx, yy)\n",
    "    p4.set_data(xx, yy)\n",
    "    return p2, xxx, yyy\n",
    "\n",
    "\n",
    "plt.clf\n",
    "loss_with_args = lambda x, y: (x ** 2)/2.0  +(y ** 2)/2.0    \n",
    "\n",
    "fig1, ax = plot_contour(loss_with_args)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel('w1')\n",
    "ax.set_ylabel('w2')\n",
    "ax.set_title('Gradient Descent - 2 Weights Loss Contours')\n",
    "\n",
    "p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "p2, = ax.plot([], [],  'r.', marker='.')\n",
    "p4, = ax.plot([], [],  'r', marker='.', alpha=.5)\n",
    "p3, = ax.plot([], [], 'r.')\n",
    "max_iter = 100\n",
    "xxx = tf.Variable(5.0)\n",
    "yyy = tf.Variable(2.0)\n",
    "xx = []\n",
    "yy = []\n",
    "loss_func = lambda: (xxx ** 2)/2.0  + (yyy ** 2)/2.0   \n",
    "\n",
    "anim2 = animation.FuncAnimation(fig1, animate_optimizer, frames=range(0, max_iter), fargs = (opt, loss_func, xxx, yyy, xx, yy, p2, p3, p4),  blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "filename = 'sgd_2d_contour_intro.gif'\n",
    "anim2.save('/home/ronen/Downloads/'+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef363c-7b9b-4158-8db5-709dbd7d0e49",
   "metadata": {},
   "source": [
    "# 3d SGD demo animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0b0c4-40be-481d-9fe0-6afabe038e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "def animate_optimizer_3d(frame, opt, loss_func, loss_func_args, xxx, yyy, xx, yy, zz, ax, p2, p3, p4):\n",
    "   \n",
    "    step_count = opt.minimize(loss_func, var_list=[xxx, yyy]).numpy()\n",
    "    ax.title.set_text('3D Plot, Frame={}'.format(frame))\n",
    "   \n",
    "    p3.set_data(xxx.numpy(), yyy.numpy())\n",
    "    p3.set_3d_properties(loss_func_args(xxx.numpy(), yyy.numpy())) \n",
    "    \n",
    "    p2.set_data(np.array(xx), np.array(yy))\n",
    "    p2.set_3d_properties(np.array(zz)) \n",
    "    \n",
    "    p4.set_data(np.array(xx), np.array(yy))\n",
    "    p4.set_3d_properties(np.array(zz)) \n",
    "    \n",
    "    xx.append(xxx.numpy())\n",
    "    yy.append(yyy.numpy())\n",
    "    zz.append(loss_func_args(xxx.numpy(), yyy.numpy())) \n",
    "\n",
    "    return p3, xxx, yyy\n",
    "\n",
    "\n",
    "def plot_loss_func_3d(loss_func_args):\n",
    "\n",
    "    xx = np.linspace(-5.5, 5.5, 100)\n",
    "    yy = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(xx, yy)\n",
    "    Z = loss_func_args(X, Y)\n",
    "    fig1 = plt.figure(figsize=(16, 6))\n",
    "    ax1 = fig1.gca(projection='3d')\n",
    "\n",
    "    surf = ax1.plot_surface(X, Y, Z, rstride=1, cstride=1, alpha=0.5, \n",
    "                           linewidth=0, antialiased=False)\n",
    "\n",
    "    ax1.set_xlabel('w1', fontsize=20)\n",
    "    ax1.set_ylabel('w2', fontsize=20)\n",
    "    ax1.set_zlabel('J(b, w)', fontsize=20)\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "    ax1.zaxis.set_ticklabels([])\n",
    "    return fig1, ax1\n",
    "\n",
    "\n",
    "\n",
    "run_params = [{'filename': 'sgd_3d_contour_intro.gif'}, {'filename': 'sgd_3d_contour_intro.gif', 'elev': 90}]\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "for params in run_params:\n",
    "\n",
    "    xxx = tf.Variable(5.0)\n",
    "    yyy = tf.Variable(5.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    zz = []\n",
    "    filename = params['filename']\n",
    "    loss_func_args = lambda xxx, yyy: (xxx ** 2)/2.0  + (yyy ** 2)/2.0 \n",
    "    loss_func = lambda: (xxx ** 2)/2.0  + (yyy ** 2)/2.0   \n",
    "\n",
    "    plt.clf\n",
    "    fig, ax = plot_loss_func_3d(loss_func_args)\n",
    "    title = ax.set_title('3D Top View')\n",
    "    z = loss_func_args(xxx.numpy(), yyy.numpy())\n",
    "    p3, = ax.plot(xxx.numpy(), yyy.numpy(), z,  'ro')\n",
    "    p2, = ax.plot(np.array([xxx.numpy()]), np.array([yyy.numpy()]), np.array([z]))\n",
    "    p4, = ax.plot(np.array([xxx.numpy()]), np.array([yyy.numpy()]), np.array([z]),  'r', alpha=.5)\n",
    "    if 'elev' in params:\n",
    "        ax.view_init(azim=0, elev=elev)\n",
    "    anim2 = animation.FuncAnimation(fig, animate_optimizer_3d, frames=range(0, max_iter), fargs =(opt, loss_func, loss_func_args, xxx, yyy, xx, yy, zz, ax, p2, p3, p4), blit=True, interval=30,repeat=True, repeat_delay=20)\n",
    "    anim2.save('/home/ronen/Downloads/'+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34575947-cfbd-4d57-86a7-633d88d21de2",
   "metadata": {},
   "source": [
    "# SGD and momentum together - no animation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d382035-86ce-4741-923f-77958f81bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradeint Descent with large step size with animation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# %matplotlib widget\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "X_COEF=1\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "x_offset = 2\n",
    "y_offset = 1.5\n",
    "\n",
    "\n",
    "loss_with_args = lambda xxx, yyy: X_COEF*(xxx)**2 + Y_COEF*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "loss = lambda: X_COEF*(xxx)**2 + Y_COEF*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "\n",
    "\n",
    "def plot_contour():\n",
    "    x = np.linspace(-5.5, 5.5, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    return fig,ax\n",
    "\n",
    "\n",
    "\n",
    "def do_optimize(opt, num_iterations, name):\n",
    "    loss = lambda: X_COEF*(xxx)**2 + Y_COEF*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "\n",
    "    fig, ax = plot_contour()\n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss, var_list=[xxx, yyy]).numpy()\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "\n",
    "\n",
    "# SGD\n",
    "num_iterations = 100\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=alpha)\n",
    "do_optimize(opt, num_iterations, name = \"SGD\")\n",
    "\n",
    "# Momentum\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9)\n",
    "do_optimize(opt, num_iterations, name = \"Momentum\")\n",
    "\n",
    "# ADAM\n",
    "num_iterations = 150\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'\n",
    ")\n",
    "\n",
    "opt = do_optimize(opt, num_iterations, name = \"Adam\")\n",
    "\n",
    "\n",
    "# ADAMAX\n",
    "\n",
    "opt = tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'\n",
    ")\n",
    "\n",
    "do_optimize(opt, num_iterations, name = \"Adamax\")\n",
    "\n",
    "\n",
    "# var1 = tf.Variable(10.0)\n",
    "# loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "# step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "# var1.numpy()\n",
    "\n",
    "# opimize(opt, ax)\n",
    "\n",
    "# Adagrad\n",
    "num_iterations=600\n",
    "opt = tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=alpha, initial_accumulator_value=0.1, epsilon=1e-07,\n",
    "    name='Adagrad'\n",
    ")\n",
    "do_optimize(opt, num_iterations, name = \"Adagrad\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15e785-2e94-4550-bfab-18a2c17510a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e98508-6419-4ac1-bb62-0253561eab79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d1f956-c002-4bd6-ae23-036ea476e2ef",
   "metadata": {},
   "source": [
    "# Optimizers with contours - Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18f3a0-029e-4065-8e96-c4523b79549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "X_COEF=1\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "x_offset = 2\n",
    "y_offset = 1.5\n",
    "\n",
    "\n",
    "\n",
    "def plot_contour(loss_with_args, title):\n",
    "\n",
    "    x = np.linspace(-5.5, 5.5, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel('w1')\n",
    "    ax.set_ylabel('b')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return fig,ax\n",
    "\n",
    "def init_animate_optimizer():\n",
    "    global xs\n",
    "    global xxx\n",
    "    global yyy\n",
    "    global opt\n",
    "    global xx\n",
    "    global yy\n",
    "    \n",
    "\n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    return p1,\n",
    "\n",
    "\n",
    "\n",
    "xx = []\n",
    "yy = []\n",
    "def animate_optimizer(frame, opt, loss_func):\n",
    "    global x\n",
    "    global xxx\n",
    "    global yyy\n",
    "    global xx\n",
    "    global yy\n",
    "    global p2, p3\n",
    "   \n",
    "    step_count = opt.minimize(loss_func, var_list=[xxx, yyy]).numpy()\n",
    "\n",
    "    p2.set_data(xx, yy)\n",
    "    p3.set_data(xxx.numpy(), yyy.numpy())\n",
    "    xx.append(xxx.numpy())\n",
    "    yy.append(yyy.numpy())\n",
    "    return p2,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233687d-ea4f-48e4-a494-0df40a057027",
   "metadata": {},
   "source": [
    "# Run optimizations - static plots with loss_diff_in_gradients - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a32a78-ca76-4e79-b49d-cdf8c2547d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "def do_optimize(loss_with_args, opt, num_iterations, name):\n",
    "\n",
    "\n",
    "    fig, ax = plot_contour(loss_with_args, name)\n",
    "\n",
    "    xx = []\n",
    "    yy = []\n",
    "    \n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "\n",
    "\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[xxx, yyy])\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "      \n",
    "    ####  Anther loss func ###############################\n",
    "    fig, ax = plot_contour(lambda x, y:  (x)**4 - 10 * (x)** 2 - 3 * (x)+ 40*(y)**2 , name)\n",
    "\n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    loss_func = lambda:  xxx**4 - 10 * xxx** 2 - 3 * xxx + 40*yyy**2 \n",
    "    \n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[xxx, yyy])\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "    \n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     xcoords = np.linspace(-3,3,100)\n",
    "#     ycoord = [loss_func_y(xcoord)  for xcoord in xcoords]\n",
    "#     ax1.plot(xcoords, ycoord)\n",
    "    \n",
    "#     loss_coord = [loss_func_y(y_coord)  for y_coord in yy]\n",
    "#     ax1.plot(yy, loss_coord, 'o-', color='red', alpha=0.6)\n",
    "#     ax1.set_xlabel('Weight')\n",
    "#     ax1.set_ylabel('Loss')\n",
    "#     ax1.set_title('Weight Loss using {name} -  Plot'.format(name=name))                  \n",
    "\n",
    "\n",
    "def run_optimization_static_contour_graph(loss_func_with_args):\n",
    "#     x=loss_func().numpy()\n",
    "#     print(x)\n",
    "#     alpha = 0.0067\n",
    "    optimizers_list = []\n",
    "    optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "    optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 100})\n",
    "    optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 450})\n",
    "    optimizers_list.append({'name': 'adamax', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 450})\n",
    "    \n",
    "    \n",
    "    for optimizer in optimizers_list:\n",
    "        print(optimizer['name'])\n",
    "        opt = optimizer['opt']\n",
    "        plt.clf\n",
    "#         fig1, ax = plot_contour(loss_with_args=loss_func_with_args, title=optimizer['name'])\n",
    "        p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "        p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "        p3, = ax.plot([], [], 'r.')\n",
    "        max_iter = optimizer['max_iter']\n",
    "        do_optimize(loss_with_args=loss_with_args, opt=opt, num_iterations=max_iter, name=optimizer['name'])\n",
    "\n",
    "\n",
    "xxx = tf.Variable(-5.0)\n",
    "yyy = tf.Variable(-2.0)\n",
    "loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "\n",
    "# loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "loss_func_with_args = lambda xxx, yyy: 1*(xxx)**2 + 40*(yyy)**2        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "run_optimization_static_contour_graph(loss_func_with_args=loss_func_with_args)\n",
    "# out_file_name_prefix = 'loss_diff_gradients_2d_contour_'\n",
    "                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6289a-d90c-4dc5-b604-1e4907305423",
   "metadata": {},
   "source": [
    "# Scratch static contour with saddle point - fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a9a51-d859-4755-9649-4e6752715e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "def plot_contour_limitted(loss_with_args, title):\n",
    "\n",
    "    x = np.linspace(1, 8, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel('w1')\n",
    "    ax.set_ylabel('b')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return fig,ax\n",
    "\n",
    "def do_optimize(loss_with_args, opt, num_iterations, name):\n",
    "#     global loss_func\n",
    "#     global xxx\n",
    "#     global yyy\n",
    "\n",
    " \n",
    "#     x=loss_func().numpy()\n",
    "#     print(x)\n",
    "\n",
    "    fig, ax = plot_contour(loss_with_args, name)\n",
    "\n",
    "    xx = []\n",
    "    yy = []\n",
    "    \n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    loss_func = lambda: 1*(xxx)**2 - 40*(yyy)**2  \n",
    "\n",
    "\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[xxx, yyy])\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "      \n",
    "    ####  Anther loss func ###############################\n",
    "    fig, ax = plot_contour_limitted(lambda x, y:  4.0*tf.cos(x-1)+tf.divide(tf.cos(2.0*np.pi*x),x)+ 40*(y)**2 , name)\n",
    "\n",
    "    xxx = tf.Variable(1.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    loss_func = lambda: 4.0*tf.cos(xxx-1)+tf.divide(tf.cos(2.0*np.pi*xxx),xxx) + 40*yyy**2 \n",
    "    \n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[xxx, yyy])\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "    \n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     xcoords = np.linspace(-3,3,100)\n",
    "#     ycoord = [loss_func_y(xcoord)  for xcoord in xcoords]\n",
    "#     ax1.plot(xcoords, ycoord)\n",
    "    \n",
    "#     loss_coord = [loss_func_y(y_coord)  for y_coord in yy]\n",
    "#     ax1.plot(yy, loss_coord, 'o-', color='red', alpha=0.6)\n",
    "#     ax1.set_xlabel('Weight')\n",
    "#     ax1.set_ylabel('Loss')\n",
    "#     ax1.set_title('Weight Loss using {name} -  Plot'.format(name=name))                  \n",
    "\n",
    "\n",
    "def run_optimization_static_contour_graph(loss_func_with_args):\n",
    "#     x=loss_func().numpy()\n",
    "    alpha = 0.0067\n",
    "    alpha = 0.02517\n",
    "    alpha = 0.001\n",
    "\n",
    "    print(alpha)\n",
    "    optimizers_list = []\n",
    "    optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "    optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 300})\n",
    "    optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 650})\n",
    "    optimizers_list.append({'name': 'adamax', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 650})\n",
    "    \n",
    "    \n",
    "    for optimizer in optimizers_list:\n",
    "        print(optimizer['name'])\n",
    "        opt = optimizer['opt']\n",
    "        plt.clf\n",
    "#         fig1, ax = plot_contour(loss_with_args=loss_func_with_args, title=optimizer['name'])\n",
    "        p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "        p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "        p3, = ax.plot([], [], 'r.')\n",
    "        max_iter = optimizer['max_iter']\n",
    "        do_optimize(loss_with_args=loss_with_args, opt=opt, num_iterations=max_iter, name=optimizer['name'])\n",
    "\n",
    "\n",
    "xxx = tf.Variable(1.0)\n",
    "yyy = tf.Variable(-2.0)\n",
    "loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "\n",
    "# loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "loss_func_with_args = lambda xxx, yyy: 1*(xxx)**2 - 40*(yyy)**2        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "run_optimization_static_contour_graph(loss_func_with_args=loss_func_with_args)\n",
    "# out_file_name_prefix = 'loss_diff_gradients_2d_contour_'\n",
    "                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afa1bb-915c-4bbc-b194-876c34397351",
   "metadata": {},
   "source": [
    "# scratch 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2eb4e2-3a53-447b-944d-89cc5a4c0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #####3D:\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "max_iter=100\n",
    "\n",
    "X_COEF=1 #20\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "max_iter = 70\n",
    "\n",
    "alpha = 0.0067\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "max_iter= 150\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def f2(x):\n",
    "    return X_COEF*(x[0]+x_offset)**2 + Y_COEF*(x[1]+y_offset)**2\n",
    "\n",
    "def grad2(x):\n",
    "    return np.array([4 * x[0]**3 - 20 * x[0] - 3, 2*Y_COEF*(x[1]+y_offset)])\n",
    "    #return np.array([4 * x**3 - 10 * x - 3, 2*Y_COEF*(x[1]+y_offset)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "v = 0\n",
    "\n",
    "def gd2_momentum_1(x, frame, alpha, grad=grad2, beta=0.9):\n",
    "    global v\n",
    "    v = beta*v + (1-beta)*grad(x)\n",
    "    vc = v/(1+beta**(frame+1))\n",
    "    x = x - alpha * vc\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "rc('animation', html='html5')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def cost_func(x, y):\n",
    "    Z = (x +x_offset)**4 - 20 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "#     Z = X_COEF*(X+x_offset)**2 + Y_COEF*(Y+y_offset)**2\n",
    "    return Z\n",
    "\n",
    "def plot_loss_func_3d():\n",
    "    xx = np.linspace(-5.5-x_offset, 5.5-y_offset, 50)\n",
    "    yy = np.linspace(-5.5-x_offset, 5.5-y_offset, 50)\n",
    "    X, Y = np.meshgrid(xx, yy)\n",
    "    Z = cost_func(X, Y)\n",
    "    fig1 = plt.figure(figsize=(16, 6))\n",
    "    ax1 = fig1.gca(projection='3d')\n",
    "\n",
    "    surf = ax1.plot_surface(X, Y, Z, rstride=1, cstride=1, alpha=0.5, \n",
    "                           linewidth=0, antialiased=False)\n",
    "\n",
    "    ax1.set_xlabel('b', fontsize=20)\n",
    "    ax1.set_ylabel('w1', fontsize=20)\n",
    "    ax1.set_zlabel('J(b, w)', fontsize=20)\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "    ax1.zaxis.set_ticklabels([])\n",
    "    plt.show()\n",
    "    return fig1, ax1\n",
    "\n",
    "# plot_loss_func_3d()\n",
    "x = np.linspace(0,5,100)\n",
    "loss = lambda x: 2*x **4 - 20 * x** 2# - 3 * x\n",
    "loss = lambda x: 4.0*tf.cos(x-1)+tf.divide(tf.cos(2.0*np.pi*x),x)\n",
    "y = loss(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb1ce7-7668-4032-9200-711c6010f7a4",
   "metadata": {},
   "source": [
    "# Run optimizations - Contour Animation with loss_diff_in_gradients - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a87eb7-10bf-4541-819d-f166565b7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_diff_in_gradients = lambda: 1*(xxx)**2 + 40*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "loss_func = loss_diff_in_gradients\n",
    "loss_with_args = lambda xxx, yyy: X_COEF*(xxx)**2 + Y_COEF*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "out_file_name_prefix = 'loss_diff_gradients_2d_contour_'\n",
    "\n",
    "optimizers_list = []\n",
    "\n",
    "optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 200})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 200})\n",
    "\n",
    "\n",
    "                   \n",
    "for optimizer in optimizers_list:\n",
    "    print(optimizer['name'])\n",
    "    opt = optimizer['opt']\n",
    "    plt.clf\n",
    "    fig1, ax = plot_contour(loss_with_args=loss_with_args, title=optimizer['name'])\n",
    "    p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "    p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "    p3, = ax.plot([], [], 'r.')\n",
    "    max_iter = optimizer['max_iter']\n",
    "    anim2 = animation.FuncAnimation(fig1, animate_optimizer, init_func=init_animate_optimizer, frames=range(0, max_iter), fargs= (opt, loss_func,), blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "    filename = optimizer['name']+'.gif'\n",
    "    anim2.save('/home/ronen/Downloads/'+out_file_name_prefix+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "    init_animate_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42ede2-c470-41e4-94e4-196dde49f4fe",
   "metadata": {},
   "source": [
    "# Run optimizations - Contout animation with loss local minima - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a57c4-73d6-4625-88b3-1dc4357ea547",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset=0\n",
    "y_offset=0\n",
    "loss_local_min = lambda:  (x +x_offset)**4 - 10 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "loss_func = loss_local_min\n",
    "out_file_name_prefix = 'loss_local_minima_2d_contour_'\n",
    "loss_with_args = lambda xxx, yyy: (x +x_offset)**4 - 10 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "\n",
    "\n",
    "optimizers_list = []\n",
    "\n",
    "optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha)', 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9)', 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')', 'max_iter': 200})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax')', 'max_iter': 200})\n",
    "\n",
    "\n",
    "                   \n",
    "for optimizer in optimizers_list:\n",
    "    print(optimizer['name'])\n",
    "    opt = optimizer['opt']\n",
    "    plt.clf\n",
    "    fig1, ax = plot_contour(loss_with_args=loss_with_args, title=optimizer['name'])\n",
    "    p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "    p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "    p3, = ax.plot([], [], 'r.')\n",
    "    max_iter = optimizer['max_iter']\n",
    "    anim2 = animation.FuncAnimation(fig1, animate_optimizer, init_func=init_animate_optimizer, frames=range(0, max_iter), fargs= (opt, loss_func,), blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "    filename = optimizer['name']+'.gif'\n",
    "    anim2.save('/home/ronen/Downloads/'+out_file_name_prefix+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "    init_animate_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320fb86-9cfa-460b-ae46-44104f9066b4",
   "metadata": {},
   "source": [
    "# DEmo multi plot animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7755499-d78b-430c-ad0a-f58f3026e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg') #use Qt5 as backend, comment this line for default backend\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = plt.axes(xlim=(0, 2), ylim=(0, 100))\n",
    "\n",
    "N = 4\n",
    "lines = [plt.plot([], [])[0] for _ in range(N)] #lines to animate\n",
    "\n",
    "rectangles = plt.bar([0.5,1,1.5],[50,40,90],width=0.1) #rectangles to animate\n",
    "\n",
    "patches = lines + list(rectangles) #things to animate\n",
    "\n",
    "def init():\n",
    "    #init lines\n",
    "    for line in lines:\n",
    "        line.set_data([], [])\n",
    "\n",
    "    #init rectangles\n",
    "    for rectangle in rectangles:\n",
    "        rectangle.set_height(0)\n",
    "\n",
    "    return patches #return everything that must be updated\n",
    "\n",
    "def animate(i):\n",
    "    #animate lines\n",
    "    for j,line in enumerate(lines):\n",
    "        line.set_data([0, 2], [10 * j,i])\n",
    "\n",
    "    #animate rectangles\n",
    "    for j,rectangle in enumerate(rectangles):\n",
    "        rectangle.set_height(i/(j+1))\n",
    "\n",
    "    return patches #return everything that must be updated\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=100, interval=20, blit=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df10848-d1c2-4367-bda2-8c13cbf6ca68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
