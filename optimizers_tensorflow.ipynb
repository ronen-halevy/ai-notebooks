{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4923e798-ffe9-4348-809a-af9235e749a0",
   "metadata": {},
   "source": [
    "# Optimizers Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bd5f181f-29b1-46a6-b4de-39cf4ccc1854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n",
      "100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a497a75cad8d4392ac9b8d7da154fac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e3740034244125a7cd155433294087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAA+ZW1kYXQAAAKhBgX//53cRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU3IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENv\n",
       "cHlsZWZ0IDIwMDMtMjAxOCAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9w\n",
       "dGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1o\n",
       "ZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2\n",
       "IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0\n",
       "X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTEyIGxvb2thaGVhZF90aHJlYWRz\n",
       "PTIgc2xpY2VkX3RocmVhZHM9MCBucj0wIGRlY2ltYXRlPTEgaW50ZXJsYWNlZD0wIGJsdXJheV9j\n",
       "b21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBiX3B5cmFtaWQ9MiBiX2FkYXB0\n",
       "PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29wPTAgd2VpZ2h0cD0yIGtleWlu\n",
       "dD0yNTAga2V5aW50X21pbj0yMCBzY2VuZWN1dD00MCBpbnRyYV9yZWZyZXNoPTAgcmNfbG9va2Fo\n",
       "ZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0wLjYwIHFwbWluPTAgcXBtYXg9\n",
       "NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAAIrNliIQAO//+906/AptFl2oD\n",
       "klcK9sqkJlm5UmsB8qYAAAMAAAMAAAMAkIRx7muVyT1mgAAAL2AJYg/wQkf8Nnp6jENCJm7Prvyp\n",
       "Bm5B8YrYeB5xbnj7ncnxgYHNiAgoeuu3pHlv3XW2tE4e6pDBzULBbhfHJMglbUhj3Lr8T9BuXr7o\n",
       "RtIschfPdfO9iigcO/M4ybVOq57C976jUjXMk299KCOhqmHUmrHjTa+ub8+VAXC2Z8Eg73NY84gQ\n",
       "mJLD4M34OsTK/vz6U/+OsY+484fZegTihc33nBomLvdoMY2DLBf+waAvupfyJpX8DS0ShQ6kE+PX\n",
       "16xGdonsswtSIiZkzZwuttbZZD6N7JlTZidU7goaRQSBKUwDkEqn//MKs6rwQTAsPG/Qbu4R7mcM\n",
       "2zt0TGMAHfWvdkeRyT1B5IIvIw7DHLT5KXQ1IUAto19SE4KT8vi8q/l3RsWKZp83XPzjrE9U0uLm\n",
       "yY8gHyZe3sm62zJbkXz/GF0SdYYu4Rls1PA7/OrKXaXrNd0xemAWI1syuCsRSHzThx85WXFF9OsL\n",
       "vzEJZDVKf7QSxqh22oK8/5Sxo5GxaE5BUwwFxURPdTjUjSpDoe30cbbNLw6rH5pA057HCVsK5nOG\n",
       "IuPcCx8yZFhm/z+WscsoG5lvSk5qIJyMyB9usyRktwuaadeE/qqgkm+mPBCjMmKDFgAZqJ/Wxh3q\n",
       "xnz32eN6rRvBecrJFXSdtX6gf+bGpzwKD+wct4oNW+68hHlFOSfI1IizbcXH4i5VBIZLjm7olbGY\n",
       "yVCJwYVWG5M93LJaukOya1pmuw/nDLbvfYCqNkW6vE2IuObCqznefQtQtfgUpX7JAwu9a6VT5Ca0\n",
       "EFiYX15PzKZQZYxarvUSGwRKhYT6k/Tgy/x1TpJ6lvP5lM8JK/aisjx3KDNDUEJLbZJiRBhLOmB7\n",
       "ybp+sJyGpt3qhJq32Yz7u0GCzH6dtIHsuujVpZU+mncZhcYjmF8b+mDv/+ZcGzPPk3JSUqpK3tu/\n",
       "NPh9pVvdt5TrjjvaLk9Fefph8UMP7e5ZRrJw2OL65eTm/9xDUXv/B5dIjKris5PhJmRucLNaPc14\n",
       "FqQN4BPikJ4ZJoT5mVf+zeczlz7XzFovevsPT/j3XVzQG/56w5dSo1glkLRsTwfk6lvGK1nEVFrV\n",
       "is2HvCy59cYzVAIYl4/f0kIQr0yHZAFvulxkQCQoAy8hFkifcK6MK1xHlV5IDzvCQ8L29aDfTybD\n",
       "kD2tbj8AzFyksYJPUNMEt4cPwvAT3z6zv8NuMF0EyJUtC492hP0h3S+yX0FMmqi17Rr59NCf/PMJ\n",
       "6hfPDDM6cBtxlyIyg7EJjQb3ETO7y2Aj6p+ZySdOSpgPeN57ubITS02csrNt1J80SZiITUqagpkV\n",
       "svDpKlGD9MIilP/A1lMzFoY2oSAAKurXBMwxtp1FEYmh723nTQ+fEkCvsi3SLL8PTBJibU4/V22t\n",
       "/remxmTCHEsLvBSDT3sFAPRDszso/viHlVE7/ajelhVyqI+1oSH37k5rY7bLimT5W2MibisirZiF\n",
       "NCPY2h9bMb3ojcAhCxddQfUtdNHZZOIa3gr1IniTR5rWW6U8sCZzJGZH76AVxowzOln9cMlyYM69\n",
       "tDi6hrOn6pebGhJVRIg3++XzYMZbthhxXIjp6MPt+hvDdoP5Wqvb/2iYCuIyfHmepyNZobzUXaOz\n",
       "BLyLVe4SwYmsKxrZHxbgWjqegLo8wnesAIYbnpZWllmLlk98bgyg/kSGyDYETw7hp5Scezr0WUln\n",
       "vB9uA02NlCHOu0sVd1Tl/wgQXJqZdI1xf+wtQtGWG8aqQFOhHr7PFOoCpdl3sRZ6Av3Xh3NGxWsR\n",
       "Yi42ytnEF2HIKsbRc6JN8GOdRFP5GqHYg/+3FPtuEfq1DTqdYT7+f3wegAkX7AU+VhGD3WHUNAg9\n",
       "MgFR8oG81wcimW7yBTZAVH+Rf4bc/1++ATmSTMDiMlxfdkSV8LbvSrKEKpQYZ3tEcaqQ62ZwARoY\n",
       "TsGEn6p7DHbH/8YLe7KCi7eioO78p95N9giXjP0uM7+HDUuNZbXplhETyttap3C023dDoexsOlqk\n",
       "1BanxmY0mUhHOG1LhZF2f910mRJ/micNNMux+dcJGAOy8l+qIPtfaLPYVEk/++frJ/6BgNRk8xqx\n",
       "CnzJlMeqI42tjAhbM0Wb/2+6iva2vNlzLbQskqMMdF2ITjiBIBpkYAQbiYWtBlcjNmGo6sKBXVkE\n",
       "oCQpOloRSZt0kQLiN2PnEXrAYlCVcRJcmHef0xUJHQPiOXRfgzQ/Y6R95AmNpYiinZaMXlIp4lz1\n",
       "FfYfjkaBLfU+LVDNKBUxHedDnEqUixG8XcPucSbQMIVRMBrzCkHmnyfBdPu4TqoYTlcgDs9RUK+7\n",
       "5fdzadusjUrIUitv6u9wLjabuQ2LTkFPrHRU1uW9WWHNi6Qk02MmRTekcUYlL3bGeJaLc2Dxfp14\n",
       "pBHAl8uDWKu8dya92COwmOLwLXsMe1t2p4q+zqK2K0ZtaoqFisFAPTV763XCql5j75KlNRJkjprv\n",
       "Hf9q6vmEi2NQAzcfGP3lmf5Xe2bLQMdtEM13BaGd7kztzsXcxBW2CbeeKljnXptQrIGBW5uZxPZV\n",
       "01uXLQRzlDNcFxmAdDozH1P3MeSweugqNUbuvc5WZkF/+0+flPoH0UBDVdyDU2mGOyZePugpd652\n",
       "AdlkaqRY9REyAWmSLChzDelW1vHe7LS9JOl78OmEqcWGQA+wM3gj0kevnKScG+PNF0ViibvJoq1F\n",
       "AwSK2c/r1CvYgKMRdpz98aQjJBHgjGn4stycjjmD3Q5Z0lDD9ga/RG6qxgmAchPA0P7ttZ0QnOdm\n",
       "vedjirgdur3fDbESqk6gPZ0ApjvOBtYEUiaow2wAWdin7kGkjW4+AGuXoL5H8iinOe03e1pRCom7\n",
       "/ZknoKNYfodUURW6n3mRa79at/ermv/Fg8sYdiE85QwArb4SSHzmD684iIfQiob+I1gnYmNTuJYr\n",
       "YKP2MWFEqNktrfnwdZh6UOWj/wGq96dNMJa2tljKZVaCt2svnk3O5fyl27wMriFndSsg9gwEdHRN\n",
       "kZHzc1JKh9muc/yMY6noQrduhmqUaMKduXDIBVKKUDMSML7221qDXl6U04Ui/cLrKZEsl9gRyBQR\n",
       "DDSLVy1DqvujbYyW481+S1LhkjoRKx6XLd8tWKxaoouTbWwL4HJTrHRpNUiaX5C6Ik5OXvVlWHEc\n",
       "4vIrgvgGoNQRepmDDtJfKfgyy/HuRUeBCaaJhiy4RviUYumlUkQw7lEIA6iq5792+Ji3IWcrqPAM\n",
       "gfQM+hmKMUJgd/qojFw4RhUaEp/RuQhtVW7r+xjUP/bMfdl8/CeOPwfuDWhnGjVoOMI7tG0OhEcG\n",
       "eAcIS3xyF+4QLe8e0hhhaLrCSJb2hKnQDWeOAbwuJr9b+e+zxIn0ibtYMYm6abGMmesrXv/AoL2j\n",
       "cU6xHQIBX3bL5DhMVVpuCsyJ66xO/Up77d9kTGNXe3t+g2KC7rcwF+UHxFefV+IWwCZGTJQTd2RB\n",
       "G1DpI5zxYftFwH3beI5T7zOY11zVNrWlW51BanwaQKvl3mOcklHbOmY6+i4T+saN+KyauVHTnf8o\n",
       "phf12YQahRdAhC3fjOzzHBW3TX5KbvNdD7a+ZQVsTz8HbYc7hyO41mwbCWAau0l3SYuYWwBuT5/9\n",
       "gZtcT878wELSIi5F1rgkYAIuAlKIR9t/ZV/Cu5+H/H3ag3Gv1XrQqH8RmeyCImJMtGoUiZ9TSBKf\n",
       "L+tI1YZbubQWRVFyKds2YKkf9Ta6OELqEeGJ98CBv6GnU0vRpU23oGdLrD5dO/aAIV0O1lCrm/cB\n",
       "Cg4P15/AC/j/yfoUfW+dLSY7CM0d9HXtJNnU/SHnNiS1+JoRq79EhsqIoJnJVA3QuDsMJrvQjc22\n",
       "X7kYanfHJjS4Ai6U1kv5HkNwFXR6UoTjRT9F7ZLBCi+AhK19UhspnCkQ5LRmo0wqzC1cUNXjT7n1\n",
       "7/2xOnLItmZh9RsZ9QvDbt017Dr3jROlwY+SIXrqDY8K7pZ+6d5RZKFHuE9xqVudWmec2RMyCU0l\n",
       "OKNvmHkT4X+NcR5Sa2iHF6ARcVtgIHgF/hj6Mvs+7U0wQf7XdbqDFF4mAk+eZWbF6YIrTw/VH+jE\n",
       "E5PykvUWVz4Lowv6lOqAniTkJKEhODej6Eh1FGFEIHESUsSCAh73FYDFY2AMjhCKoCjW0BiczKwT\n",
       "2G1649PTKD5uOkXvehjXFB6sb/98dCkFzg8DcWuSsjkMtdUnsSrWK6hYHS1pUEl0kGbMUI8FeA50\n",
       "oc3KTiGjEFAZRsoUgKHw9yloP5HDBJHsB8VeICDiz+6HieVL8+om1tEeE83WzqQkKYqQVz4WbnsC\n",
       "IIgpCZad7o9dY16llkUbpAV9zSlkLx+y4+jek4f02C61hgtyjn09lT2jUDsbCDW1ZDKlb1ttVl/0\n",
       "xMvfIplM+knipIZQbFfdlwV0aIn8+SZUu65bohZ+4yCKNh5NaapS009cJ0mwPJwuGv2NZiOBQwaG\n",
       "PU+Xxmubta0mch52YSaAlG+++sPxiIhPh6C+LNYpVvnEdHWDpKUhV3nX08FvamLnhRRRrF1+uL6o\n",
       "Y8Z1hCJdnsA2HUjqZHl8/0pSduCW0+AuPIoVApqjvqzRR4QTCtoM/XByuQJJ7KwXpM0MGDTSe7Cc\n",
       "AAqgCxNtJorSIwvzK1KNUJZDK2VbQe/okc4lfv4pcakZK51oLWCs2CNESCyaGFhmTFtzxW6EiP8c\n",
       "J/MYk/dZ7npUE0eFBX0HmYPcTBzcIH/hQlXZITr/BnkiOQ+UkaGRMpvkB7RMlGMBR3s9yjWbQ2oP\n",
       "pG+0Ie7SU8wRCvlxP9eP43YcLHIGEsSRfm8U7UUWsMi367f/odk0PgzrF06LIw4crhUpN9lmN0Q4\n",
       "COuXf9SCTcE1PnPN5e7MuyOpd3cs0piE9Dretb9BfOHmnBTFiotvfuv6xoEELt/yUM2MUeMMsSww\n",
       "LVLMjXWzRr8mGrqTLV7PrIazLR0Jsc1yrSoeO3/kdPEu+qbRTfpCZ8Pli+k5I4rCMEiMEdaUM1au\n",
       "TYYIL0Je+SxlS11nabdhPbl6kP3HCmz16st+FDfesqfw8TwDGsK5ZXN20beNo8k738dalJdIcqED\n",
       "cFdcGPuWuz/qEv4dV+bCkZrzxibdBykQlkL9PsECg6QtedEmE6LC4aG2mfdl4uC6tMo82eVS1RX1\n",
       "oTLM6CGo3TxLXcXwavX0ParKzFkEvIZxbYneGdgCVQXwmHJa5oJ6eEcVNrZdhhRpsADmzROjSd70\n",
       "1JrsyJeHhr4D0868PFIV38yKjN6j26o+u8+kBycdkPpwTu7rseMmZyEUqdkjbDlSnLCWbF+1N5si\n",
       "RAcY+xXEvSFWS8nEGlNocf2rRL6tJvtKrYIw9NdWgtUSO77VK92FpG/VVvJ7V+YaEHK+3fZasYqp\n",
       "FaOuPwJjXTSoJSEy4Yz3WeDU6Wcl9gyOxyoyiF0sq9IHdtY4kZdih+lT72CujQbTHA+Ej8mplz50\n",
       "ncR1pLc6w/CNlYhT1ALPfqX7Ur6YBRgOy5e+vKFbY0kjtOyqAGmatBUMQThKUl14JZB5J0noF/ue\n",
       "HUA3W9Vr9H2k1Xrwe43OwB1sBm5YU5dn2obboUR/IT4Czb7cb99Ka4+CP6Y6ereiCxKyDDo7t353\n",
       "FfuzLLpdhMiSOyxeuZdbFmoZ5FF3zkgcoDrRBAB8epfJaDl0J5m4ssjuq7/F67lAnQNgdtemRrk+\n",
       "m9l7vSzUzJyV6k1amNVkxk//QiLLb3QLg1G284qZEsZv7bD2ASk5PZMzsmmZE1Km3Ljn8GvQHf4o\n",
       "VGeJ0jR3DTSZhMffhEzUkTppzkxfxHaVV8ueYY+Q7JReROAkU73KOt49MytZFaeKWJGg61MiYIAS\n",
       "7eq0z4QFrFLNeQCwUPsv0s/sMUloGkvVelYycqXsPjf/V3cI4au7FZ5IKNFXbFtF5sDb2mj6yxn7\n",
       "6ZEL/mmpBwj/U8fuhBVzp7jqIPqfgMV2FkpWITYpxmcdxX9ioDXAa507CNBQCAz7MCGHqf5RPBdT\n",
       "UOaQv5TEIdQE6uSgVj9b2UAmwgtujK2w4R3/JLk9Vg9s0f6691paC2JfVz48AznIZ1RnekaU/Pu2\n",
       "yHW+8YdKczKTwbCVRcBM4MGjA4An9lXg/kD1KXI+RSPLhXIKO3h4gvXefdLpy2w5hFXzbUALSAZm\n",
       "OiQCFpm/7r6C6fh8nNaSzWjbFUHHnY4BM9BcuMWaE6eP+S5cP98ax402lG+ryEJjxNKS0NXStYat\n",
       "K1Edzt/KNDkk5fKkxRjLSyI9jCqXHQgk7PSlRzULsePFehnyplGQiQX1Vj+93Ld6G5wr51/4945Z\n",
       "381IOjHGmwcfzfoipeX4SFGYcNU+QSkPevn+xb3n9zC+EbRicd1oPwh7xlW2Q3gjp60vlWQjOR1v\n",
       "ijf+PlgrL8eLpMvxNOa7EyLboSFJ62YnZptNJNlYULTrIivbNfywIBSXjMM4Mp/C0V4ovGPr6CVa\n",
       "zGwQSJ9YDuJgdHMjXXiumU72lhP6QVmUbBfnQ3zsOfbG8ZPtEsl6TAJ4L9GZJSMf+2I+mJYZRQvN\n",
       "DcidW3MrzdXPQ1QLEV3yyhiikYK9p/bSm3MAHMmA/yqNgHWJsjRNNnvk6TJcI4zIFmDZkBEYEX7N\n",
       "JLm2Rrjn8+BsubzLR47HD+C5YoYjAlNp0labHV3icH4BXh95MonrKMFIdkcnB8+aAhSF/mtnxT9t\n",
       "P441QwUu0bmghvSCPNSbulD/rvj2PW4i5TFW27LjOTHLMnPRi5nv9K31Vuu6eB2EPZRwU1JhYk0w\n",
       "9UoEUC3osoq23k6pG1gRECVdzSiu9gvP1vfqTZCjNJ26JlmZ0cpeJhmdmMPYDN2l4qZqsI86W2x2\n",
       "UvBjK+CUyQNBRfvLmAteWGSP7GXY0MhkAPEdLakeIOZHdDzuQP+JJUpFBaRv6jFkIYUPypqRBVk5\n",
       "QPJLSVbgU/+49AnCsJKq0a6kSSgtq+A8GuF93Auvzxvebab+MiUvAryJ0OP48MG+b2PJ7VCh3Pdr\n",
       "63SnSYUK1LdLMvQNaD5eIeD9YWqZwKs93TvFqVCMxE/rgRyKfVNi3inMgGkLV2RpOYSLwT/80YJn\n",
       "GgejjcCWJLPtOYEwwhOqTsylBWu5fxWtFx2H7BoQT0c0e9s73BUNyv3QJW/B0Jrd7Adnm1gjtWQy\n",
       "CwPxd9jQn8fgnNtJZVhqc+n3f/cbOj8KLBdwXRRk73XYvialyjNLIm0HbcSsQlw5lafXJDnYuA4q\n",
       "mVgWdBHc63nyADQabRpUtCpwQGAEQhngp6jD8nAR23QT8xdhjPGxZmTKCeOim1gTf9j4EGEv+rHh\n",
       "EZ+6qPc++oZlfgcF7Fe+X8Hr2pRqA1XAMcOBo6nlTYJUwghIgxXKNTmxBGOFCAmXdwnXhuHX8ljy\n",
       "oxHeNfKLaaNUMl6FKCCFalN2y/SIF1aFs0gU/KBtGLP8YAjuslqbiw9y7QwvS99PmOHLnfqckOlC\n",
       "7jQp1AdGYo2IaLBC17GE6vl4g43mt6Y613FH0NK9rRxUoJeBJ4S1NgObFHm9rHdSI3kkn9YbaRAe\n",
       "GHpQlhr1Xu0cOij3QW0iOhDjw8ZisT5SahXEbAyRJZqqZ2zBMYXMfH3h0R/fLHehc02NvKJSfZwu\n",
       "UrSgd5JKkmJQNA7fRxGa2Y04GE7CfD6Q6cbvSSjKnT6jSwq1dswVb02RHP/Qd0B+pNbs73LVYdw2\n",
       "KcUMr5JXucFCKrux2bReeXNnvDJUCBZI/YF+yvHO1LXSjdYgEEc0xfYRTbpbaimLXFAXfrCsn/XZ\n",
       "NJwVtLhbHOMr1ejCBj1IAGw/ecZSrlte6+avz6IaUCMV6VhFCZtZ9WOX3CJPEynGXjkYvfznwSRR\n",
       "4EpUcr/jc7qpcxus3Fi15caRN6qnrft1St4vrY0n9Wzd3UOzUOIYR4lOqw7asv2pAEPeDUgE/UT5\n",
       "D9tOYyGIrcwDmKzKF983QmvEVsODty8zfOee0/yTbdvKyVsgUvg4hoRmtBAeaS1dRZqx/QKRLdJ/\n",
       "F4boO3w23b5m9e1MENZLzrb6brX4uAV65FWlY42OxUNAuim+5RX/p+3nzpTCAm+TEJe3u0tmkcis\n",
       "3tBgTMnieWG45ZmiQIBsamtfKMiPXTth8ZZSsTHhFmTopA2nE3XbVHjBoXJKacl5gFkfMBONbdzV\n",
       "LriqSFau5W3CJTMJXpfR64g16yE/Vkiw9CVB+PLYpRIII4DUVwKJlA5Zd77qfh8pAWzZ2PvczcDj\n",
       "xP7igenmhgthbpg4N5eJnvZsx82wCP4/yQHusklt/bQNQh8kDOBvHsJUBgvARmrUz3PXYSdUeZHl\n",
       "4+iFXCZRxLhOOzosmo21x5THMlz3uB9QOyGpRgqQmFILBKQUj4Fyr5tErCBN0k1SuJyf5sMMTVM6\n",
       "Wf2xHgOSQTCwKGRYLW0hqSBM+Qsqd/VQKw75FmzH4xYZkPYAKjtCgzz9NeR5yt+pABntRQ9xyJbI\n",
       "9eV+naEhWFSSapxFUUZSd1JObkxsTR5XBldrpvwCsOzx/6fQUC4RetTMKUYWrent6wkFmxAKSP9z\n",
       "ci5hUw4nhdAx8ZqDh4MDzpLw62j8+pZ7H4zDiCSkTbHNqIOgyMAvbiWXihLFQLxB7wsRlr34LJ+y\n",
       "TmRk6/0SQXm1cg+o2NV8oc01Iyby1ckA5qkYBIid0ql0OokuR/cxtC/p+278PPeWwI9XS8PwyEzW\n",
       "kddzWfJ91v+cn8le+qABWsaKEzLJ1UuFMRVpa+wPUb8JkwEKWZ+0yCcl6nQ7sVtNecT3tCpijm5n\n",
       "VMBDwZxDZUUAzt5SRYhT/V/bGaTwulJTUjdf0CxbQr4iqpEIoK/wqajfnyN/+pW1i+G47noU65Lj\n",
       "yjcGGiejqivshya12fCgMjkE9WD5WlgJxVeZ5GNA0mjaTCHRF/Hx/c5JQe/UsmMACFrmT2mxc8aV\n",
       "1pY26iwrWoI5SfoYUAZqSC3zB/a5wbX65xga2l42AOmvwPUJg64A4x7keppfUFZKa/2h+OaoAx1D\n",
       "ZhhZj+RhrdokcR53zw4QrU50oHAamSfYgI1b+IuhJaq7Jb+RKU8gydVnXJBCqU6JIKMWEihjSzRr\n",
       "ovA0pRMQ4uCTu9niD4MuJeJO/9zDJoq1BMh/MdBBYkAj4ykgl7K+xILAc2RmGnY8pAjJg6+Lm8E2\n",
       "LVKnL4szLNyCi9vM9WBdcA4oUJoBMPw1tJnFn+pidlWsB2h4M3obpNGEKAP+nklIvlEdkfGOLZ8G\n",
       "+n1dT6M35kQtvHPueIkr96mN1ZnZwSKC1R8fI5jn5hxyDC0/HmUGhA3scqfkYRbrFXwAQeLsfj9k\n",
       "vsCzHrR7Sd5U+soSZWfYM/ZV0+Zgl7p8vLMtRdM5rdu4Yrf/lbYcdiQZj0uLiTx5j9pOYfyGBsA/\n",
       "y+ibePPxuYailr8dOat5nGpAY6SWFsAOQEQ3OtH3HhCZ1KI2WeBuvQnFO/PNhpm4uQASdOWMdVGL\n",
       "hIiZoLKMwXFh5UBNsCGLu9DawKVqEJHaMcO2xe2lbY/f/NVbjJ1Qa5g61hSYUx69kTD3FK10y5pb\n",
       "uFNFWNwPmW+y6Gw4FVB92lM9ljJJXYg+Y3Gvesucxg3VwKA7RqjPpxdXD01k/BXqpwg78ZMbw+1f\n",
       "zY3H1eC3TzeFQ4oaqVBvBbnVa+2lC2nux1/t5+6RqM4falGJx5Uvv2X0YEQhpe9JeoqZ6xvV6W86\n",
       "M7FdKmEf5SZmePAFCepIaIzKzv+sxad5RG5itzces2glSASmWdC01g+idW5r5jfYmQPzgleMkNWB\n",
       "cbKaq8+v9usKcAC5WrEbxOlN0kC+7tBfK2jW4KBsn6PfK7J3BpgQWUCVwk/X2B1Q/UbisgAm60wq\n",
       "VjNsqsMsEiETcvCa3Knu8pMpeJiaFs5zertUA5b9uwPX6hJvd4M9WUd7NCeoAc9f2WduuZzAvYZS\n",
       "Oy8py6DTL4kj7sEjLXq7//6Ld/+K+Csgh5B5ZAgrRrrCYz52ECzOzPo1z/cYzVuwMK5drS66L0e8\n",
       "rV9SvQhQJMRhzTEvMNOTErmDFqq9cdxgtBcj++lVNDIEU+fv2Xv1O6PYELuyB4T92eMtzp8d7jQ5\n",
       "t/74HZdoCqwhSl7sHSlvYJZSGaGtg9inJaLzF+igVpCKLPUtyAePyZ6yNcysDAwy/yjw9OB6FKfB\n",
       "Jo+qtITxkgyptFPSl7+3Ge3m8eT/RykopykxSz8RWB6VhVTIYww7OXhRfBGu4/BO4n/3/w0boul9\n",
       "cte0pFeiL0lWr0aQEa/wdntX2CLu9HI2vp7KkTTVVZa2GFwYcN+VZsjyRYwrrnaAJyeOyZnfSdcY\n",
       "jzbHZ2h20QU+i0AzA4mDBRrIfTuAXWFCWvlqJbMYmYhQCuGwVTJjPmtZ/kJAEnZMmKCnKLzc5nhq\n",
       "g/wLblgNVartSLUdI6fnSDsIbJqH+3N7n9evhq8A4f7bMzUmdyCGSdSZkGxQQCoR/5qVBXmlN5Qw\n",
       "iPF7nvGVI9bzza2gOuppyYt7zt8ddprFw1F2H6RJx3dYsQU/GC/63/2H2Z2nBxWlgnZhxgYTFvt+\n",
       "CNE4DaGp9hUrZ8z0JSgB03cuY/ZYh2Y7dSUmPbWdP7somnr2Def97+RDP0x3b818wcNMa7nGHzyH\n",
       "vFsfw65rNz5bNVa/QUuWWoTFd2YuH8wB70vMoCTK9QtHpTXit6UCU9OzJF3YKAIb0zZ3X50Avhxc\n",
       "3PuWeDZGs2eZUqZpJSHkfMIs4x7eA2f1g0d0RCLOKIXjleT18KQzOGKFjnsUrWOOP8eRcFp5Bgi8\n",
       "yCBvM/fWTlvuxdg2IEiqCtqkgESEEHVHE8NDPecLRyyL1qyGgJZb4hbafH29FNDp23BEsJ6H2OIU\n",
       "XCO9cSb//M4C4DwTVDdkG8NMxdKo9Lu9ZMq5nrYgB+ly29eJdZ5PCgn0VN59mgXZl0bv6qDhwbaw\n",
       "Ur4zhSA5LAWAOZyBl6jn7b1UwaviWD7sB2FWUHZpTMfhAtGUDgKdCFyUKP5Kj2a9j5caOvfGyvNr\n",
       "1uWxN8p2j1D/L2saAHlHEFgVUU/ns0h4O1GhIyIcWvQ9jiqThPgqV6uB0iyYPSx6voS/WkMinej+\n",
       "4OAApPrBJ9T5el1rMV16RT0sr3S74r2+DwgqwmpxsHjz664CsVS/EzwN5LkM4ue4oJLpXDxJ0LAC\n",
       "J/YJPPOFe4GLsFQfVNf7LtE6wEPfIedjlWlqMmBv0dV3Gal276h2tBzOMhO2HGTUPv0ISpx7JK6h\n",
       "R0sgVIU9BVtVhbrug2fvtuXod/0PeiVxBJQdGV5fgf529BYisop8tel7OM5tnB4tWP8LkdrNzdj+\n",
       "kl31Yw5hTivjwEixynHuyRUFbWNHKPK2noGLYDzvzNdOL63SBykiLZoP1mTtX0LfRHEUrwHvZT4x\n",
       "y0Zr5g/zTs6Z089aDEr95c8Ip4sBa2gRs1MpgaSRt0LryK0hVDBSEtQX0EFFp518X6exngyg8JCK\n",
       "QnfsyQx+BTf8qBPf7qtAvOq0saoH6/hAgS1PoF/h4Twj42hwOMkjhzHc+MFdRrX36l5I03HYrTsF\n",
       "gmH3PYDROTaAJVDFa+xtJ9g5gUSqiW/BIdycAMm0k61IiylOvETxZ+NGhiMCh/MhzlEho8V513AO\n",
       "QQCcEwTT8ckd2gSKZVg7AS8QW/WL6hvfQyoLcIt3iLsfAKzhThYDf5k1SRXGA+itzfj3fpUoUvb1\n",
       "GFAn4Fbga/IQbfXetoDGY7Nbc1uM3ORhVwoaREGKge+ZWyMUkfCttDPrZnrlzWvi6Be4oaayp5vG\n",
       "Md3b2p/5aor4ETZYcr5djulk007S1IjHU7dDl8y7fB8LmkmiiIN8CPc6B7VkOZR0fTJtRoSs7RmX\n",
       "WfMmilXOgkNy+sa8W4DjZ8cFFpUi97JAMEALvCAAAUMAAAMLQZojbEP//qmWAAhPzE2VUcfAIQJA\n",
       "8v2qmH1H5UupprKfqAlS6gB+nFdq4fEHZZDvIDj9gOeA/h4/wXdVRVM/OpUPGlD/Rpd0VdjdX0ya\n",
       "JO07wvYge92IkL9aQe+ov96/F7M1zf/RQpMvsWwg6Ny4znu5pgd0feXV68QrzjVhgPXhMoQl+TcY\n",
       "XMsMQ9vrg5kfrPxgLU35IR7ECiG5+Ku9qW1Yc23o40Ux8KL1UxD1cmdOAAUld9dw0OcYteFsNRRq\n",
       "EURtz240QMaGNl2THYFeh11jRdeSpQxCtlAGczRNdzdWdzz5eRae9cjLZtMnXhVX+DldXXjPEcg6\n",
       "a5SQ4wywYNDbzukRDnJm9wAhJy2YCkyvhj50fTBjf1Kw/qdNrhrjQPDA5MJGk3Ql/uzhy8jt+5Sy\n",
       "rkKAWXmmVHV6xXz41Tu1L4WLlMxgMmOc64bjVbStYeYCRXUkx7ys0hqFXvEpNi1EepKHRkQw+HF0\n",
       "qixGoa5ErUxGY4OeiYC3z3JP/zorOZuNJ0C1X3aP8tCUBdmP+cmSwvyxslesNdYbHZ6o8lbies3p\n",
       "6eRbCwoPER7zaC73xS2TNl3N6MXCGPIlM46vwWPzsZ9BB7bPDkFPrK0Q6zY4kELXnEGZMVpIlKNl\n",
       "k8b+xa2thihaOuHXJol5zFHYiyC6mKtGbqyA9+4BK/22I3T+3SbDr+rzg/FHhcfPmwP9YQaHA+72\n",
       "AErE1h+tN+rMhGCCt8wV5Pn2IX00LTXUHzSVTU9ChdS2/35QLwBJ0S1EmPOtjsFdh93TZ3+Gctk/\n",
       "NOBwsDH3n/KPhr0CgEC6rqBFBDPhfihrtxFp0iS/Y81vD2Okmr6wD/AaJJ323NyOizxAXz3Qa3UQ\n",
       "dyGDpLvwHe7t9Gl7m6reBPYvGCST6buBKK0MD1WsxmdwaCPnucoB4R6fg7Hg8mg38QakYixQo2W+\n",
       "ihLeYYwW+ApPPfCcZ5HKfSDgIK0Mjaxk/KcmlzB13+KsSlMVvFJyGKYex3uQvMQjE7e2JAXGOD9K\n",
       "SV6f0zOEYLX7+EZzb2JmYn4AAACvQZ5BeIX/AAnzDRfhBBNWnCX8B+OyVoxxiUu8ZDnVrN8D3QlC\n",
       "UfABbY871fPZ3fSzmFvoinPzMg/dA4iv/jpTpVCvqQiEo5DxwzPFTdw2lOwD3zCTZ6CX//eprDTR\n",
       "KahYaoovZ6oNbqvxcSOuRzR/FxO0h3z222K6L8/DCv5s1jIPHI4jafht3v/+owNbaW78IeBjBWUr\n",
       "RYmxJsLBLmepIOtjAHYZXRuhIU2fiTRqQQAAAFIBnmJqQr8AAAS3X52uiD6l7CAACU0z7GmgCpR6\n",
       "jwqJQNKlZ7fPoFy4VN1iXc4fTgb8CCobFPZkPV6BLVwqhFp8+bha0w3YkSVy2BiO+XI0IdrIAAAB\n",
       "3UGaZ0moQWiZTAh3//6plgAAYz20HXL81tQQGriJANOuLaRa703ygwi6J5FLQW8pLwcQ0Q+uMQt4\n",
       "Ts7KhSyxkRLzSkHROe97VG+H3eRrEJa/szA7qJmvXPcnzOP/gLnrF1OQ15FaM8yEjOvXhXUm3f+A\n",
       "7+ZNFbjSF9JczsT/VbDqJTZXKu2cphnScpIxzyjWcfWsvIAkYqZBcWvTzUUoYFvxMz06iLBaItUj\n",
       "bJoJF5/YyouSz54Id/vMJtjK9aB7u09jvtX+rWVWiQth3klYowUXZ7UszC2pidL4XhKG0z9R7x2Y\n",
       "/XdPAtN3gzAcnEdArHL+yKrrCf3mrS7zjmjC83QOvcWqNzmIbAQhHidlIwjOw0vm5io1D+GQ2IU0\n",
       "Za1e7q7NwF5bUq502y/8+o6YcSCdZ+A8pPBZxCX/auuBpqf1E+96b+KYa6732cLoRPlLWlG4oz9l\n",
       "RaOTIpwAxn4xbqcGFeGBcTrG/G34BdaXXqxxZMpMu/FOFBaPzV9apc8vpifPUOD8ehPkBYGCeU5c\n",
       "QD3IlCj9BstBFD7isbGjDBjmeB9c8Vy5jHIOpiyyxOb3BdIMyD/udMiLt3Ie8My7VQKhtwyYMjjN\n",
       "NbriASqPMJRa7+9FTJJU3bYzGHHvdQAAAJpBnoVFESwz/wAAbBhxbs3FtQNf561TAdiezkoAWz1G\n",
       "13J2fGmnn67gXWAVoh+uHQuaJAngugkZg1vDpJ6dNDMW/+gIKmCrPY5zHW0lAH6scykCEhuB+fD7\n",
       "/lxceNYAzSmDAJ5tRD9BqVvkAP9lAHD8CuqwCORERqsbvo3tOUk1UlZg0LlxQmerWlBpwzYrXOu7\n",
       "RD0mwkNfI2LLAAAALgGepHRCvwAAn0XkAoR1QDvvrlCEFsprN1TTzaa6hraIYc5fbWERdkf2qPPq\n",
       "r48AAABHAZ6makK/AAAEt1+dgNL+Snf4lzpHyUZhKyAEm+LbgycXAwJItxIO5m6hSetOKovIrCmw\n",
       "rVRQqtv2Oz9bHQaASHLtPLiMB+UAAAFwQZqrSahBbJlMCHf//qmWAAADAAADAHn7VooSzgIVdAJM\n",
       "aDoECYHwsBk9BLcbYaBDi6siz4X0qdxxUqzcnh4GUFmyk6YXIHNlO3JSBmt/zi5YhB5yH6UZhTJ9\n",
       "LR6DAq7qEX/2ulaLjCGL0jW8Vz/lZqQ9Z7zT4DGvFF6kZtdTwZA3oMNjEiaMA8E5SRUILjyKNrGd\n",
       "Sjt9QuHTEM/31X+wCccvI9IWZ+/10ep80Wb0FuAoLaIO6t2+S8A9NbjhdtcGWzjiiZ3Fq771Y2Rg\n",
       "opuoovcGYJaLh2RGha1Wxk1DN3/ZBkfOaFr4BDVDinwC4xCO7ppBIr2ZnrrLFeA/SpLbE8bvmVvl\n",
       "zLx43qy22R34XIPsqKWyUj4ApNb12iZQoSdp9jAJCBB5P2WBYvJrtMf4dOT3QZ0r8ydLYdEERoBy\n",
       "YFnh98M135ffZlOU8sqZKzxXRI6aGaah1P5HmeEpp/Ib1T0FCL/XZdMcvdsgHwhO0poAAACYQZ7J\n",
       "RRUsM/8AAGwYcW7NxbUDYISJq735MjgCJj2nyoZEngPYYt7ezc9jrvmvZbRwbl/eP7ZP0kdF2rSl\n",
       "X/YLrUejMs0f05LP1TbbqeTz1knZlrGH0QJNJksby23bGEtBIzorftpO5ZOdpmxaIo1PDorKWmWX\n",
       "/CtKSyfoWJUKEgiSoLJ3IW7UnYGzYdo2i/GnkDeHfTDnGOoAAABLAZ7odEK/AAAEtdCNgBxYzp0O\n",
       "UyBb/d7QAfhI6eoNdr9ZnGkBhd0aarlnecKGlaIZ9a6PlW0xVCTJIvoxx75+GhsPbUUR+iWzdy/z\n",
       "AAAAJwGe6mpCvwAABLdfnYAcTQaVx8W7INHqsAATv3aBCiEjCa6PJYDWLgAAAI9Bmu1JqEFsmUwU\n",
       "TDv//qmWAAADAAADAC7sSPQ0PRABLV0Oaat6GAuEq0Sz/ZcYAbMGQgbEqsBZDrDNqFnh/YeYOvm3\n",
       "aXGkA1IONX94uyG1aV4J4vRKkpTa/dF1VKUgaLlNFVSoumJ7SaOBTTxxOCnbp/LMJLBOX27xKIZl\n",
       "P5A+LqCpAp+gAOKVXTGBouzViwAAADIBnwxqQr8AAAS4Mx6g7d0jHWi2oEOOnCABntfRf1IPzAaA\n",
       "AZJ+T2AbayBBimeaXYJ38wAAAKVBmw9J4QpSZTBSw//+qZYAAAMAAAMALuolCE+TOAdACWUDBvSE\n",
       "ndXMo6kwbHk3WXa12SLKXN3BPLFSR5dtP+mR7msEiooqBa9La/7s0ELS+eIrHzC+3qSEy/xkjXeU\n",
       "LlyYQCX6kCoi2RpdI8A9FkiEAZS/Ei4jcGsLLK0QI5wsH+PP998uXxIHIAzvtVJHSpl/jr1uNgve\n",
       "AYU5zqZqgPDdwMG6ijkAAAA4AZ8uakK/AAADAAAXSC/M/FK/k6gUIATS3173beZENAi5ICA9DsC6\n",
       "2PxIgzBDMAnwHnPSfk7RwDMAAAClQZszSeEOiZTAh//+qZYAAAMAAAMAMF/L6T9AsRSTYqaeQa5Q\n",
       "N6kwCF3Xy1zDnspOZeAlKRVMTWcf42ZREZ6Ny/vF1ZTfu7pApjkVQruh0MwjvKbnTV3F1xDXKel0\n",
       "s0sa6vugSRtrT1+YGMSSBine56LV96KPSyoP2rBbTkFHVrXxeLhMvGoAzTB6zzlqsRxYIeFgLc2b\n",
       "X+1wWox7NT9lQnjLAC/AAAAAR0GfUUUVPDP/AABsBRQUAD99UZ2XaDQChmxwCOFIAPwjVhBHB3OT\n",
       "1KPKS9+y1eOne7+jsSSQtUhV37LsH5vjJeichS2LHxKAAAAAMwGfcHRCvwAAAwAAAwBNWpDgBBjA\n",
       "i5LCeWc/93oO5jHaZmQj9at+Lfa4l9ocnQLGzNovjwAAACgBn3JqQr8AAAMAAAMATYMmZOF/PD1r\n",
       "IKkAJowCW5CkfjwmzU+uFAHTAAAA2UGbd0moQWiZTAh///6plgAAAwAAAwAwXutP9Xsx0gDNraJa\n",
       "aeAjf/+hQojaiF5s8LH4RLrdUbjNqX2ogQ1o1CdMLEmRJIPqtvgmGpIUESZcjcnB8rbp1epr7t4z\n",
       "2cqZOrDtZyPaZB9i+Z1FXPeshDCXkvfHCumeGLtOOzgs7DT2plRdwy4BE4TJZkl6anvLEDcoDevm\n",
       "r69dz9YT0JEikQQXde7PD7JCPs9shdgHc3OONEoIoMhaybNgYtqjPP5TyhViEGdKP6F8UOhLugq9\n",
       "4gymWotHCO1wyykAAAAxQZ+VRREsM/8AAGwYcWQANM7Qx+LQdqJiigAP5fEgiAfkuvc2wEU2qJHJ\n",
       "PUP+RemDVQAAADQBn7R0Qr8AAAMAAAMATXw/mrMwTpaJwAmpImwByzoodsTErTahUpz97t6VnS08\n",
       "Rs1NmDs0AAAAGQGftmpCvwAAAwAAAwAcWu7DF6sSqdYf55kAAACPQZu7SahBbJlMCH///qmWAAAD\n",
       "AAADABGBDKYjDfIcACDMjAx5xXAt7YFQCTtuaR/VrGH2rpRsO5NGuBwHI9J6ilPye4I4zq5KhCBv\n",
       "aNMZsfaw7Mq3GlNIBiPIaNaW+z6APw0a6t+QOPdMxmn3k4flpxr925LleU0ngiKL/qd4Kx5VBpiC\n",
       "RkENAO3yb37qnzEAAAA7QZ/ZRRUsM/8AAGwYcWQANM7Qx9+Hb/tAB+Kq8hi7igGZQSAcpUCjrxoc\n",
       "fOGn6rAt8D46sQhDQ56Nz6YAAAAzAZ/4dEK/AAADAAADAEyVSOhhOuAgAtKML4nNsAshFbnGJSDY\n",
       "ds70o5dihV8fgKJzl5OdAAAAGwGf+mpCvwAAAwAAAwBMlUjocb5ztmNHWE5pYAAAAK5Bm/9JqEFs\n",
       "mUwIf//+qZYAAAMAAAMAEYMGePAEbNL9QAOWx6Cpwf76GhYny5MlCa+vgYi0r8aA2UtYoNlSLFqU\n",
       "NdGYzLOI33DA/Tvz/8Yo+XD5CKOnvctrjBXf21yttLbIvKaaPS2B+O3iuxnUYvcu7TVetb3TYVTi\n",
       "9SxplsPjBlTjFBWftpVqKSv77rCM8yJtrWY5XLASbAVhqhbB0bvH92UDKudDuFuPnvhxrp0AAAAu\n",
       "QZ4dRRUsM/8AAGwYcWQANM7QzqshZVx6WMAAlhA+3mEmFonZDxcPwu72tqgYdwAAACMBnjx0Qr8A\n",
       "AAMAAAMATV0MuzXteQAeIJhy1kVmGiCYFUhH0AAAABYBnj5qQr8AAAMAAAMATXX9v/9f/DHrAAAA\n",
       "dUGaI0moQWyZTAh///6plgAAAwAAAwARgyTcYAVyXD9ySK+2O9xKiD2x2cSnwpL4BR5U8i9N1thd\n",
       "Wla9cn40rmlIjIPQWIX3a1aOwmEJxhtaN1pZkT9nN4pBqOtJcKpfaKS1Dr83sI98TKkGiqsSrACP\n",
       "brDjgQAAAChBnkFFFSwz/wAAbBhxZAA0ztDOzBBT2UKQoACUFUwK2Df77YnSCzuAAAAAFwGeYHRC\n",
       "vwAAAwAAAwBNXQy+f/eVC2VhAAAAFgGeYmpCvwAAAwAAAwBNdf2//1/8MesAAACHQZpnSahBbJlM\n",
       "CH///qmWAAADAAADABGDJKngC8qW/2WfThEpTAMsU5Iws6iUigrSu32QiWeEW9KvIVRmVuJ3std4\n",
       "nSin1tT43T0OPzAN4S6PYCafjNF/ghrilNZFbv2oL1l41n7kDfkUiKuYZumBl5CfCnlk4+gcDmyU\n",
       "k4lRHCzAIcqee1mPAAAALUGehUUVLDP/AABsGHFkADTO0M7MEFCq8hLzRHaACtmwg5gZmes2qUag\n",
       "qx6ssQAAABcBnqR0Qr8AAAMAAAMATV0Mvn/3lQtlYQAAABcBnqZqQr8AAAMAAAMATXX9w3i3VXQ8\n",
       "rQAAABxBmqtJqEFsmUwIf//+qZYAAAMAAAMAEYdXjmE4AAAAFUGeyUUVLDP/AABsGHFkADTO0MQK\n",
       "CAAAABMBnuh0Qr8AAAMAAAMATJVIs3+BAAAAEwGe6mpCvwAAAwAAAwBMlUizf4AAAACQQZrvSahB\n",
       "bJlMCH///qmWAAADAAADABGDQVPAF5T6GlVaIN2C9Pq3+h+P21k7+V6rEJDO2uzX8AJ8TxGrT+rE\n",
       "CdSfXBogUoX5u1TPuYGL2EZ7vtUMJZBKdWu+g15SyUXUThLRdVa9jS9EQikX3aUu2l7XAYZvg17F\n",
       "O6SDNVcaAncN6MFxPOQMtLFFFzVJrWY4AAAAHEGfDUUVLDP/AABsGHFkADTO0M6rIWVsTzrdIyEA\n",
       "AAAWAZ8sdEK/AAADAAADAE1dDL5/95z+UwAAABIBny5qQr8AAAMAAAMATXX54bkAAAAgQZszSahB\n",
       "bJlMCH///qmWAAADAAADABGDu+ABuV2frYAAAAAXQZ9RRRUsM/8AAGwYcWQANM7QzswPjPkAAAAS\n",
       "AZ9wdEK/AAADAAADAE1dCOG5AAAAEgGfcmpCvwAAAwAAAwBNdfnhuAAAAIBBm3dJqEFsmUwIf//+\n",
       "qZYAAAMAAAMAEYNBU8AXoEn1/9SSf1NveEOHs47h/vsSu7awAjD5A3KQy5nKqUt5lmrQx7QJVwO/\n",
       "zkWL40OavDj3p8uMVYiyBpm5YKJiTrNybG0vOgwSl7VUq+lCqP3nz5EjPD26QsIjtWigET0DJjtZ\n",
       "jgAAABxBn5VFFSwz/wAAbBhxZAA0ztDOzBBXTZAsuEZBAAAAEgGftHRCvwAAAwAAAwBNXQjhuAAA\n",
       "ABcBn7ZqQr8AAAMAAAMATXX9w3i3VxrjgQAAACFBm7tJqEFsmUwIf//+qZYAAAMAAAMAEQR4UAAJ\n",
       "cept70EAAAAXQZ/ZRRUsM/8AAGwYcWQANM7QzswPjPkAAAASAZ/4dEK/AAADAAADAE1dCOG5AAAA\n",
       "EgGf+mpCvwAAAwAAAwBNdfnhuAAAABlBm/9JqEFsmUwIf//+qZYAAAMAAAMAACzhAAAAF0GeHUUV\n",
       "LDP/AABsGHFkADTO0M7MD4z5AAAAEgGePHRCvwAAAwAAAwBNXQjhuAAAABIBnj5qQr8AAAMAAAMA\n",
       "TXX54bgAAAAZQZojSahBbJlMCH///qmWAAADAAADAAAs4QAAABdBnkFFFSwz/wAAbBhxZAA0ztDO\n",
       "zA+M+QAAABIBnmB0Qr8AAAMAAAMATV0I4bkAAAASAZ5iakK/AAADAAADAE11+eG4AAAAGUGaZ0mo\n",
       "QWyZTAh///6plgAAAwAAAwAALOEAAAAXQZ6FRRUsM/8AAGwYcWQANM7QzswPjPkAAAASAZ6kdEK/\n",
       "AAADAAADAE1dCOG5AAAAEgGepmpCvwAAAwAAAwBNdfnhuQAAABlBmqtJqEFsmUwIf//+qZYAAAMA\n",
       "AAMAACzgAAAAF0GeyUUVLDP/AABsGHFkADTO0M7MD4z5AAAAEgGe6HRCvwAAAwAAAwBNXQjhuQAA\n",
       "ABIBnupqQr8AAAMAAAMATXX54bgAAAAZQZrvSahBbJlMCH///qmWAAADAAADAAAs4AAAABdBnw1F\n",
       "FSwz/wAAbBhxZAA0ztDOzA+M+QAAABIBnyx0Qr8AAAMAAAMATV0I4bkAAAASAZ8uakK/AAADAAAD\n",
       "AE11+eG5AAAAGUGbM0moQWyZTAh///6plgAAAwAAAwAALOAAAAAXQZ9RRRUsM/8AAGwYcWQANM7Q\n",
       "zswPjPkAAAASAZ9wdEK/AAADAAADAE1dCOG5AAAAEgGfcmpCvwAAAwAAAwBNdfnhuAAAABlBm3dJ\n",
       "qEFsmUwId//+qZYAAAMAAAMAACzgAAAAF0GflUUVLDP/AABsGHFkADTO0M7MD4z5AAAAEgGftHRC\n",
       "vwAAAwAAAwBNXQjhuAAAABIBn7ZqQr8AAAMAAAMATXX54bkAAAAZQZu7SahBbJlMCHf//qmWAAAD\n",
       "AAADAAAs4QAAABdBn9lFFSwz/wAAbBhxZAA0ztDOzA+M+QAAABIBn/h0Qr8AAAMAAAMATV0I4bkA\n",
       "AAASAZ/6akK/AAADAAADAE11+eG4AAAAGUGb/0moQWyZTAhv//6nhAAAAwAAAwAAWUEAAAAXQZ4d\n",
       "RRUsM/8AAGwYcWQANM7QzswPjPkAAAASAZ48dEK/AAADAAADAE1dCOG4AAAAEgGePmpCvwAAAwAA\n",
       "AwBNdfnhuAAAABhBmiNJqEFsmUwIV//+OEAAAAMAAAMABU0AAAAXQZ5BRRUsM/8AAGwYcWQANM7Q\n",
       "zswPjPkAAAASAZ5gdEK/AAADAAADAE1dCOG5AAAAEgGeYmpCvwAAAwAAAwBNdfnhuAAAB9Ztb292\n",
       "AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAATiAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAA\n",
       "AAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAHAHRy\n",
       "YWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAATiAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAA\n",
       "AAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAACgAAAAeAAAAAAACRlZHRzAAAAHGVsc3QAAAAA\n",
       "AAAAAQAAE4gAAAQAAAEAAAAABnhtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAADIAFXEAAAA\n",
       "AAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAYjbWluZgAAABR2\n",
       "bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAF43N0\n",
       "YmwAAACzc3RzZAAAAAAAAAABAAAAo2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAACgAHgAEgA\n",
       "AABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAxYXZjQwFk\n",
       "AB7/4QAYZ2QAHqzZQKA9oQAAAwABAAADACgPFi2WAQAGaOvjyyLAAAAAHHV1aWRraEDyXyRPxbo5\n",
       "pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAABkAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAD\n",
       "KGN0dHMAAAAAAAAAYwAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAoAAAAAAQAABAAAAAAB\n",
       "AAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEA\n",
       "AAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAA\n",
       "CgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAAC\n",
       "AAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAA\n",
       "AAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAA\n",
       "AAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAA\n",
       "AAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAA\n",
       "AQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAAB\n",
       "AAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEA\n",
       "AAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAA\n",
       "BAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAK\n",
       "AAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIA\n",
       "AAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAA\n",
       "AAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAZAAAAAEAAAGkc3RzegAAAAAAAAAAAAAAZAAA\n",
       "JVwAAAMPAAAAswAAAFYAAAHhAAAAngAAADIAAABLAAABdAAAAJwAAABPAAAAKwAAAJMAAAA2AAAA\n",
       "qQAAADwAAACpAAAASwAAADcAAAAsAAAA3QAAADUAAAA4AAAAHQAAAJMAAAA/AAAANwAAAB8AAACy\n",
       "AAAAMgAAACcAAAAaAAAAeQAAACwAAAAbAAAAGgAAAIsAAAAxAAAAGwAAABsAAAAgAAAAGQAAABcA\n",
       "AAAXAAAAlAAAACAAAAAaAAAAFgAAACQAAAAbAAAAFgAAABYAAACEAAAAIAAAABYAAAAbAAAAJQAA\n",
       "ABsAAAAWAAAAFgAAAB0AAAAbAAAAFgAAABYAAAAdAAAAGwAAABYAAAAWAAAAHQAAABsAAAAWAAAA\n",
       "FgAAAB0AAAAbAAAAFgAAABYAAAAdAAAAGwAAABYAAAAWAAAAHQAAABsAAAAWAAAAFgAAAB0AAAAb\n",
       "AAAAFgAAABYAAAAdAAAAGwAAABYAAAAWAAAAHQAAABsAAAAWAAAAFgAAABwAAAAbAAAAFgAAABYA\n",
       "AAAUc3RjbwAAAAAAAAABAAAALAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1k\n",
       "aXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMjku\n",
       "MTAw\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x7f9bb5038a30>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "var = tf.Variable(5.0)\n",
    "loss = lambda: (var ** 2)/2.0         # d(loss)/d(var1) = var1\n",
    "tt = []\n",
    "for j in range(100):\n",
    "    step_count = opt.minimize(loss, [var]).numpy()\n",
    "    tt.append(var.numpy())\n",
    "# Step is `- learning_rate * grad`\n",
    "# print(var.numpy())\n",
    "print(step_count)\n",
    "\n",
    "lossf = lambda x: (x ** 2)/2.0         # d(loss)/d(var1) = var1\n",
    "\n",
    "x=list(np.linspace(-6, 6.0, 100))\n",
    "y = []\n",
    "for xx in x:\n",
    "    y.append(lossf(xx))\n",
    "\n",
    "ll = []\n",
    "for t in tt:\n",
    "    ll.append(lossf(t))\n",
    "#     y.append(loss(xx))\n",
    "# y = [xx for xx in x]\n",
    "# plt.plot(x, y)\n",
    "# plt.scatter(x,y)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.scatter(tt, ll)\n",
    "\n",
    "xx = []\n",
    "x_sgd = tf.Variable(5.0)\n",
    "def animate_optimizer(frame):\n",
    "    global x\n",
    "    global x_sgd\n",
    "    global yyy\n",
    "    global xx\n",
    "    global yy\n",
    "    global p2, p3\n",
    "    global opt\n",
    "#     global loss\n",
    "    global lossf\n",
    "\n",
    "    loss = lambda: (x_sgd ** 2)/2.0      \n",
    "    step_count = opt.minimize(loss, var_list=[x_sgd]).numpy()\n",
    "\n",
    "    \n",
    "    p3.set_data(x_sgd.numpy(), lossf(x_sgd.numpy()))\n",
    "    xx.append(x_sgd.numpy() )\n",
    "    loss_y = [lossf(xt) for xt in xx]\n",
    "    p2.set_data(xx, loss_y)\n",
    "    return p2,\n",
    "\n",
    "\n",
    "plt.clf\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "x_sgd = tf.Variable(5.0)\n",
    "p1, = ax.plot([x_sgd], [lossf(x_sgd)], 'kx')\n",
    "p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "p3, = ax.plot([], [],  'r.', marker='o', alpha=.5, ms=10)\n",
    "max_iter = 100\n",
    "anim2 = animation.FuncAnimation(fig, animate_optimizer, \n",
    "                                frames=range(0, max_iter),  blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "filename = '/home/ronen/Downloads/sgd_1d_intro.gif'\n",
    "anim2\n",
    "# anim2.save(filename, dpi=80, writer='imagemagick', fps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34575947-cfbd-4d57-86a7-633d88d21de2",
   "metadata": {},
   "source": [
    "# SGD and momentum together - no animation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d382035-86ce-4741-923f-77958f81bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradeint Descent with large step size with animation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "X_COEF=1\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "x_offset = 2\n",
    "y_offset = 1.5\n",
    "\n",
    "\n",
    "loss_with_args = lambda xxx, yyy: X_COEF*(xxx)**2 + Y_COEF*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "loss = lambda: X_COEF*(xxx)**2 + Y_COEF*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "\n",
    "\n",
    "def plot_contour():\n",
    "    x = np.linspace(-5.5, 5.5, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    return fig,ax\n",
    "\n",
    "\n",
    "\n",
    "def do_optimize(opt, num_iterations, name):\n",
    "    loss = lambda: X_COEF*(xxx)**2 + Y_COEF*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "\n",
    "    fig, ax = plot_contour()\n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss, var_list=[xxx, yyy]).numpy()\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "\n",
    "\n",
    "# SGD\n",
    "num_iterations = 100\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=alpha)\n",
    "do_optimize(opt, num_iterations, name = \"SGD\")\n",
    "\n",
    "# Momentum\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9)\n",
    "do_optimize(opt, num_iterations, name = \"Momentum\")\n",
    "\n",
    "# ADAM\n",
    "num_iterations = 150\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'\n",
    ")\n",
    "\n",
    "opt = do_optimize(opt, num_iterations, name = \"Adam\")\n",
    "\n",
    "\n",
    "# ADAMAX\n",
    "\n",
    "opt = tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'\n",
    ")\n",
    "\n",
    "do_optimize(opt, num_iterations, name = \"Adamax\")\n",
    "\n",
    "\n",
    "# var1 = tf.Variable(10.0)\n",
    "# loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "# step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "# var1.numpy()\n",
    "\n",
    "# opimize(opt, ax)\n",
    "\n",
    "# Adagrad\n",
    "num_iterations=600\n",
    "opt = tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=alpha, initial_accumulator_value=0.1, epsilon=1e-07,\n",
    "    name='Adagrad'\n",
    ")\n",
    "do_optimize(opt, num_iterations, name = \"Adagrad\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf15e785-2e94-4550-bfab-18a2c17510a2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e98508-6419-4ac1-bb62-0253561eab79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d1f956-c002-4bd6-ae23-036ea476e2ef",
   "metadata": {},
   "source": [
    "# Optimizers with contours - Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e18f3a0-029e-4065-8e96-c4523b79549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "X_COEF=1\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "x_offset = 2\n",
    "y_offset = 1.5\n",
    "\n",
    "\n",
    "\n",
    "def plot_contour(loss_with_args, title):\n",
    "\n",
    "    x = np.linspace(-5.5, 5.5, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel('w1')\n",
    "    ax.set_ylabel('b')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return fig,ax\n",
    "\n",
    "def init_animate_optimizer():\n",
    "    global xs\n",
    "    global xxx\n",
    "    global yyy\n",
    "    global opt\n",
    "    global xx\n",
    "    global yy\n",
    "    \n",
    "\n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    return p1,\n",
    "\n",
    "\n",
    "\n",
    "xx = []\n",
    "yy = []\n",
    "def animate_optimizer(frame, opt, loss_func):\n",
    "    global x\n",
    "    global xxx\n",
    "    global yyy\n",
    "    global xx\n",
    "    global yy\n",
    "    global p2, p3\n",
    "   \n",
    "    step_count = opt.minimize(loss_func, var_list=[xxx, yyy]).numpy()\n",
    "\n",
    "    p2.set_data(xx, yy)\n",
    "    p3.set_data(xxx.numpy(), yyy.numpy())\n",
    "    xx.append(xxx.numpy())\n",
    "    yy.append(yyy.numpy())\n",
    "    return p2,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5233687d-ea4f-48e4-a494-0df40a057027",
   "metadata": {},
   "source": [
    "# Run optimizations - static plots with loss_diff_in_gradients - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2a32a78-ca76-4e79-b49d-cdf8c2547d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n",
      "sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138ff7bca0064232b64b1ce47437700a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ac9af437d64324a90f5aa1432b259c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "momentum\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3153fb3be2428785dc1139de8c342f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a7549c6e2441beaccef2b561fcb51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943d9d3b69474b1fac45be7b89abca41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364ace12bc314fd992bfd0a6d76d4dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adamax\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c2d7e2d661474881b97a6621ec58f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675e06e0b09a409aad9674f5537fef98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "def do_optimize(loss_with_args, opt, num_iterations, name):\n",
    "#     global loss_func\n",
    "#     global xxx\n",
    "#     global yyy\n",
    "\n",
    " \n",
    "#     x=loss_func().numpy()\n",
    "#     print(x)\n",
    "\n",
    "    fig, ax = plot_contour(loss_with_args, name)\n",
    "\n",
    "    xx = []\n",
    "    yy = []\n",
    "    \n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "\n",
    "\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[xxx, yyy])\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "      \n",
    "    ####  Anther loss func ###############################\n",
    "    fig, ax = plot_contour(lambda x, y:  (x)**4 - 10 * (x)** 2 - 3 * (x)+ 40*(y)**2 , name)\n",
    "\n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    loss_func = lambda:  xxx**4 - 10 * xxx** 2 - 3 * xxx + 40*yyy**2 \n",
    "    \n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[xxx, yyy])\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "    \n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     xcoords = np.linspace(-3,3,100)\n",
    "#     ycoord = [loss_func_y(xcoord)  for xcoord in xcoords]\n",
    "#     ax1.plot(xcoords, ycoord)\n",
    "    \n",
    "#     loss_coord = [loss_func_y(y_coord)  for y_coord in yy]\n",
    "#     ax1.plot(yy, loss_coord, 'o-', color='red', alpha=0.6)\n",
    "#     ax1.set_xlabel('Weight')\n",
    "#     ax1.set_ylabel('Loss')\n",
    "#     ax1.set_title('Weight Loss using {name} -  Plot'.format(name=name))                  \n",
    "\n",
    "\n",
    "def run_optimization_static_contour_graph(loss_func_with_args):\n",
    "#     x=loss_func().numpy()\n",
    "#     print(x)\n",
    "#     alpha = 0.0067\n",
    "    optimizers_list = []\n",
    "    optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "    optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 100})\n",
    "    optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 450})\n",
    "    optimizers_list.append({'name': 'adamax', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 450})\n",
    "    \n",
    "    \n",
    "    for optimizer in optimizers_list:\n",
    "        print(optimizer['name'])\n",
    "        opt = optimizer['opt']\n",
    "        plt.clf\n",
    "#         fig1, ax = plot_contour(loss_with_args=loss_func_with_args, title=optimizer['name'])\n",
    "        p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "        p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "        p3, = ax.plot([], [], 'r.')\n",
    "        max_iter = optimizer['max_iter']\n",
    "        do_optimize(loss_with_args=loss_with_args, opt=opt, num_iterations=max_iter, name=optimizer['name'])\n",
    "\n",
    "\n",
    "xxx = tf.Variable(-5.0)\n",
    "yyy = tf.Variable(-2.0)\n",
    "loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "\n",
    "# loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "loss_func_with_args = lambda xxx, yyy: 1*(xxx)**2 + 40*(yyy)**2        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "run_optimization_static_contour_graph(loss_func_with_args=loss_func_with_args)\n",
    "# out_file_name_prefix = 'loss_diff_gradients_2d_contour_'\n",
    "                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6289a-d90c-4dc5-b604-1e4907305423",
   "metadata": {},
   "source": [
    "# Scratch static contour with saddle point - fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "602a9a51-d859-4755-9649-4e6752715e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n",
      "0.001\n",
      "sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6416725c5eb6439db16590ef60f2f947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c8b4d1407f4d829ad3f7f299a6aa57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "momentum\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecfbe8b9d7b41d198017306f02458c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3e626c01d74a53b2d60791486e7059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ac0996fb364733a151000f7c0adeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f078053065403a83582f12a5f79a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adamax\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b095c6eaaab9455bbb1a24cd2741c6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb40612dc7247ed857158f82e05e2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "def plot_contour_limitted(loss_with_args, title):\n",
    "\n",
    "    x = np.linspace(1, 8, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel('w1')\n",
    "    ax.set_ylabel('b')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return fig,ax\n",
    "\n",
    "def do_optimize(loss_with_args, opt, num_iterations, name):\n",
    "#     global loss_func\n",
    "#     global xxx\n",
    "#     global yyy\n",
    "\n",
    " \n",
    "#     x=loss_func().numpy()\n",
    "#     print(x)\n",
    "\n",
    "    fig, ax = plot_contour(loss_with_args, name)\n",
    "\n",
    "    xx = []\n",
    "    yy = []\n",
    "    \n",
    "    xxx = tf.Variable(-5.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    loss_func = lambda: 1*(xxx)**2 - 40*(yyy)**2  \n",
    "\n",
    "\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[xxx, yyy])\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "      \n",
    "    ####  Anther loss func ###############################\n",
    "    fig, ax = plot_contour_limitted(lambda x, y:  4.0*tf.cos(x-1)+tf.divide(tf.cos(2.0*np.pi*x),x)+ 40*(y)**2 , name)\n",
    "\n",
    "    xxx = tf.Variable(1.0)\n",
    "    yyy = tf.Variable(-2.0)\n",
    "    xx = []\n",
    "    yy = []\n",
    "    loss_func = lambda: 4.0*tf.cos(xxx-1)+tf.divide(tf.cos(2.0*np.pi*xxx),xxx) + 40*yyy**2 \n",
    "    \n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[xxx, yyy])\n",
    "        xx.append(xxx.numpy())\n",
    "        yy.append(yyy.numpy())\n",
    "\n",
    "    ax.plot(xx, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "    \n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     xcoords = np.linspace(-3,3,100)\n",
    "#     ycoord = [loss_func_y(xcoord)  for xcoord in xcoords]\n",
    "#     ax1.plot(xcoords, ycoord)\n",
    "    \n",
    "#     loss_coord = [loss_func_y(y_coord)  for y_coord in yy]\n",
    "#     ax1.plot(yy, loss_coord, 'o-', color='red', alpha=0.6)\n",
    "#     ax1.set_xlabel('Weight')\n",
    "#     ax1.set_ylabel('Loss')\n",
    "#     ax1.set_title('Weight Loss using {name} -  Plot'.format(name=name))                  \n",
    "\n",
    "\n",
    "def run_optimization_static_contour_graph(loss_func_with_args):\n",
    "#     x=loss_func().numpy()\n",
    "    alpha = 0.0067\n",
    "    alpha = 0.02517\n",
    "    alpha = 0.001\n",
    "\n",
    "    print(alpha)\n",
    "    optimizers_list = []\n",
    "    optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "    optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 300})\n",
    "    optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 650})\n",
    "    optimizers_list.append({'name': 'adamax', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 650})\n",
    "    \n",
    "    \n",
    "    for optimizer in optimizers_list:\n",
    "        print(optimizer['name'])\n",
    "        opt = optimizer['opt']\n",
    "        plt.clf\n",
    "#         fig1, ax = plot_contour(loss_with_args=loss_func_with_args, title=optimizer['name'])\n",
    "        p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "        p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "        p3, = ax.plot([], [], 'r.')\n",
    "        max_iter = optimizer['max_iter']\n",
    "        do_optimize(loss_with_args=loss_with_args, opt=opt, num_iterations=max_iter, name=optimizer['name'])\n",
    "\n",
    "\n",
    "xxx = tf.Variable(1.0)\n",
    "yyy = tf.Variable(-2.0)\n",
    "loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "\n",
    "# loss_func = lambda: 1*(xxx)**2 + 40*(yyy)**2  \n",
    "loss_func_with_args = lambda xxx, yyy: 1*(xxx)**2 - 40*(yyy)**2        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "run_optimization_static_contour_graph(loss_func_with_args=loss_func_with_args)\n",
    "# out_file_name_prefix = 'loss_diff_gradients_2d_contour_'\n",
    "                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afa1bb-915c-4bbc-b194-876c34397351",
   "metadata": {},
   "source": [
    "# scratch 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5c2eb4e2-3a53-447b-944d-89cc5a4c0d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1764fc285c3c49039acc55da7669b9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9bbbdcca60>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # #####3D:\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "max_iter=100\n",
    "\n",
    "X_COEF=1 #20\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "max_iter = 70\n",
    "\n",
    "alpha = 0.0067\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "max_iter= 150\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def f2(x):\n",
    "    return X_COEF*(x[0]+x_offset)**2 + Y_COEF*(x[1]+y_offset)**2\n",
    "\n",
    "def grad2(x):\n",
    "    return np.array([4 * x[0]**3 - 20 * x[0] - 3, 2*Y_COEF*(x[1]+y_offset)])\n",
    "    #return np.array([4 * x**3 - 10 * x - 3, 2*Y_COEF*(x[1]+y_offset)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "v = 0\n",
    "\n",
    "def gd2_momentum_1(x, frame, alpha, grad=grad2, beta=0.9):\n",
    "    global v\n",
    "    v = beta*v + (1-beta)*grad(x)\n",
    "    vc = v/(1+beta**(frame+1))\n",
    "    x = x - alpha * vc\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "rc('animation', html='html5')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def cost_func(x, y):\n",
    "    Z = (x +x_offset)**4 - 20 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "#     Z = X_COEF*(X+x_offset)**2 + Y_COEF*(Y+y_offset)**2\n",
    "    return Z\n",
    "\n",
    "def plot_loss_func_3d():\n",
    "    xx = np.linspace(-5.5-x_offset, 5.5-y_offset, 50)\n",
    "    yy = np.linspace(-5.5-x_offset, 5.5-y_offset, 50)\n",
    "    X, Y = np.meshgrid(xx, yy)\n",
    "    Z = cost_func(X, Y)\n",
    "    fig1 = plt.figure(figsize=(16, 6))\n",
    "    ax1 = fig1.gca(projection='3d')\n",
    "\n",
    "    surf = ax1.plot_surface(X, Y, Z, rstride=1, cstride=1, alpha=0.5, \n",
    "                           linewidth=0, antialiased=False)\n",
    "\n",
    "    ax1.set_xlabel('b', fontsize=20)\n",
    "    ax1.set_ylabel('w1', fontsize=20)\n",
    "    ax1.set_zlabel('J(b, w)', fontsize=20)\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "    ax1.zaxis.set_ticklabels([])\n",
    "    plt.show()\n",
    "    return fig1, ax1\n",
    "\n",
    "# plot_loss_func_3d()\n",
    "x = np.linspace(0,5,100)\n",
    "loss = lambda x: 2*x **4 - 20 * x** 2# - 3 * x\n",
    "loss = lambda x: 4.0*tf.cos(x-1)+tf.divide(tf.cos(2.0*np.pi*x),x)\n",
    "y = loss(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eb1ce7-7668-4032-9200-711c6010f7a4",
   "metadata": {},
   "source": [
    "# Run optimizations - Contour Animation with loss_diff_in_gradients - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a87eb7-10bf-4541-819d-f166565b7b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4e46a7dc0640df8a6fdae43057ab99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "momentum\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed13b3babf00437db787956e22d4bcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c18db7eac794ce7975286839d695c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615ad57dec714122bfd99e751aa4654c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_diff_in_gradients = lambda: 1*(xxx)**2 + 40*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "loss_func = loss_diff_in_gradients\n",
    "loss_with_args = lambda xxx, yyy: X_COEF*(xxx)**2 + Y_COEF*(yyy)**2         # d(loss)/d(var1) = var1\n",
    "out_file_name_prefix = 'loss_diff_gradients_2d_contour_'\n",
    "\n",
    "optimizers_list = []\n",
    "\n",
    "optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 200})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 200})\n",
    "\n",
    "\n",
    "                   \n",
    "for optimizer in optimizers_list:\n",
    "    print(optimizer['name'])\n",
    "    opt = optimizer['opt']\n",
    "    plt.clf\n",
    "    fig1, ax = plot_contour(loss_with_args=loss_with_args, title=optimizer['name'])\n",
    "    p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "    p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "    p3, = ax.plot([], [], 'r.')\n",
    "    max_iter = optimizer['max_iter']\n",
    "    anim2 = animation.FuncAnimation(fig1, animate_optimizer, init_func=init_animate_optimizer, frames=range(0, max_iter), fargs= (opt, loss_func,), blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "    filename = optimizer['name']+'.gif'\n",
    "    anim2.save('/home/ronen/Downloads/'+out_file_name_prefix+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "    init_animate_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42ede2-c470-41e4-94e4-196dde49f4fe",
   "metadata": {},
   "source": [
    "# Run optimizations - Contout animation with loss local minima - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029a57c4-73d6-4625-88b3-1dc4357ea547",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_offset=0\n",
    "y_offset=0\n",
    "loss_local_min = lambda:  (x +x_offset)**4 - 10 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "loss_func = loss_local_min\n",
    "out_file_name_prefix = 'loss_local_minima_2d_contour_'\n",
    "loss_with_args = lambda xxx, yyy: (x +x_offset)**4 - 10 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "\n",
    "\n",
    "optimizers_list = []\n",
    "\n",
    "optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha)', 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9)', 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')', 'max_iter': 200})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax')', 'max_iter': 200})\n",
    "\n",
    "\n",
    "                   \n",
    "for optimizer in optimizers_list:\n",
    "    print(optimizer['name'])\n",
    "    opt = optimizer['opt']\n",
    "    plt.clf\n",
    "    fig1, ax = plot_contour(loss_with_args=loss_with_args, title=optimizer['name'])\n",
    "    p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "    p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "    p3, = ax.plot([], [], 'r.')\n",
    "    max_iter = optimizer['max_iter']\n",
    "    anim2 = animation.FuncAnimation(fig1, animate_optimizer, init_func=init_animate_optimizer, frames=range(0, max_iter), fargs= (opt, loss_func,), blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "    filename = optimizer['name']+'.gif'\n",
    "    anim2.save('/home/ronen/Downloads/'+out_file_name_prefix+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "    init_animate_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320fb86-9cfa-460b-ae46-44104f9066b4",
   "metadata": {},
   "source": [
    "# DEmo multi plot animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7755499-d78b-430c-ad0a-f58f3026e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg') #use Qt5 as backend, comment this line for default backend\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = plt.axes(xlim=(0, 2), ylim=(0, 100))\n",
    "\n",
    "N = 4\n",
    "lines = [plt.plot([], [])[0] for _ in range(N)] #lines to animate\n",
    "\n",
    "rectangles = plt.bar([0.5,1,1.5],[50,40,90],width=0.1) #rectangles to animate\n",
    "\n",
    "patches = lines + list(rectangles) #things to animate\n",
    "\n",
    "def init():\n",
    "    #init lines\n",
    "    for line in lines:\n",
    "        line.set_data([], [])\n",
    "\n",
    "    #init rectangles\n",
    "    for rectangle in rectangles:\n",
    "        rectangle.set_height(0)\n",
    "\n",
    "    return patches #return everything that must be updated\n",
    "\n",
    "def animate(i):\n",
    "    #animate lines\n",
    "    for j,line in enumerate(lines):\n",
    "        line.set_data([0, 2], [10 * j,i])\n",
    "\n",
    "    #animate rectangles\n",
    "    for j,rectangle in enumerate(rectangles):\n",
    "        rectangle.set_height(i/(j+1))\n",
    "\n",
    "    return patches #return everything that must be updated\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=100, interval=20, blit=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914ef588-d897-4949-9b7f-e3fce1e9df1e",
   "metadata": {},
   "source": [
    "# Illustrate multi plot shared axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69564696-0547-4b57-8561-f411be5196ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # Some example data to display\n",
    "# x = np.linspace(0, 2 * np.pi, 400)\n",
    "# y = np.sin(x ** 2)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# gs = fig.add_gridspec(3, hspace=0)\n",
    "# axs = gs.subplots(sharex=True, sharey=True)\n",
    "# fig.suptitle('Sharing both axes')\n",
    "# axs[0].plot(x, y ** 2)\n",
    "# axs[1].plot(x, 0.3 * y, 'o')\n",
    "# axs[2].plot(x, y, '+')\n",
    "\n",
    "# # Hide x labels and tick labels for all but bottom plot.\n",
    "# for ax in axs:\n",
    "#     ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ff8d5-a046-4522-8618-b02e2b1a7060",
   "metadata": {},
   "source": [
    "# Scratch illustrate animation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
