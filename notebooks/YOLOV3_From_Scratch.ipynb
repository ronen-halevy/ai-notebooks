{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOV3-From-Scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHsVwaI+wTEJoilibgTXtU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronen-halevy/ai-notebooks/blob/main/notebooks/YOLOV3_From_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#config\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "\n",
        "__C                           = edict()\n",
        "# Consumers can get config by: from config import cfg\n",
        "\n",
        "cfg                           = __C\n",
        "\n",
        "# YOLO options\n",
        "__C.YOLO                      = edict()\n",
        "\n",
        "# Set the class name\n",
        "# __C.YOLO.CLASSES              = \"./data/classes/coco.names\"\n",
        "# __C.YOLO.ANCHORS              = \"./data/anchors/basline_anchors.txt\"\n",
        "# __C.YOLO.STRIDES              = [8, 16, 32]\n",
        "# __C.YOLO.ANCHOR_PER_SCALE     = 3\n",
        "# __C.YOLO.IOU_LOSS_THRESH      = 0.5\n",
        "\n",
        "# Train options\n",
        "# __C.TRAIN                     = edict()\n",
        "\n",
        "# __C.TRAIN.ANNOT_PATH          = \"./data/dataset/yymnist_train.txt\"\n",
        "# __C.TRAIN.BATCH_SIZE          = 4\n",
        "# # __C.TRAIN.INPUT_SIZE            = [320, 352, 384, 416, 448, 480, 512, 544, 576, 608]\n",
        "# __C.TRAIN.INPUT_SIZE          = [416]\n",
        "# __C.TRAIN.DATA_AUG            = True\n",
        "# __C.TRAIN.LR_INIT             = 1e-3\n",
        "# __C.TRAIN.LR_END              = 1e-6\n",
        "# __C.TRAIN.WARMUP_EPOCHS       = 2\n",
        "# __C.TRAIN.EPOCHS              = 30\n",
        "\n",
        "\n",
        "\n",
        "# TEST options\n",
        "__C.TEST                      = edict()\n",
        "\n",
        "__C.TEST.ANNOT_PATH           = \"./data/dataset/yymnist_test.txt\"\n",
        "__C.TEST.BATCH_SIZE           = 2\n",
        "__C.TEST.INPUT_SIZE           = 544\n",
        "__C.TEST.DATA_AUG             = False\n",
        "__C.TEST.DECTECTED_IMAGE_PATH = \"./data/detection/\"\n",
        "__C.TEST.SCORE_THRESHOLD      = 0.3\n",
        "__C.TEST.IOU_THRESHOLD        = 0.45\n",
        "\n",
        "######\n",
        "flags.DEFINE_string('classes', './data/classes/coco.names', 'path to classes file')\n",
        "flags.DEFINE_string('anchors', './data/anchors/basline_anchors.txt', 'path to classes file')\n",
        "flags.DEFINE_string('strides', [8, 16, 32], 'number of strides')\n",
        "flags.DEFINE_string('anchors_per_scale', 3, 'anchors_per_scale')\n",
        "flags.DEFINE_string('iou_threshold', 0.5, 'anchors_per_scale')\n",
        "flags.DEFINE_string('score_threshold', 0.3, 'score_threshold')\n",
        "\n",
        "#train\n",
        "\n",
        "\n",
        "flags.DEFINE_string('train_annotation_file_path', './data/dataset/yymnist_train.txt', 'train_annotation_file_path')\n",
        "flags.DEFINE_string('batch_size', 4, 'batch_size')\n",
        "flags.DEFINE_string('input_size', [416], 'input_size')\n",
        "flags.DEFINE_string('data_aug', True, 'data_aug')\n",
        "flags.DEFINE_string('learning_rate_init', 1e-3, 'learning_rate_init')\n",
        "flags.DEFINE_string('learning_rate_end', 1e-6, 'learning_rate_end')\n",
        "flags.DEFINE_string('warmup_epochs', 2, 'warmup_epochs')\n",
        "flags.DEFINE_string('epochs', 30, 'epochs')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l7f2YlPEPMD9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#core common\n",
        "#! /usr/bin/env python\n",
        "# coding=utf-8\n",
        "#================================================================\n",
        "#   Copyright (C) 2019 * Ltd. All rights reserved.\n",
        "#\n",
        "#   Editor      : VIM\n",
        "#   File name   : common.py\n",
        "#   Author      : YunYang1994\n",
        "#   Created date: 2019-07-11 23:12:53\n",
        "#   Description :\n",
        "#\n",
        "#================================================================\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
        "    \"\"\"\n",
        "    \"Frozen state\" and \"inference mode\" are two separate concepts.\n",
        "    `layer.trainable = False` is to freeze the layer, so the layer will use\n",
        "    stored moving `var` and `mean` in the \"inference mode\", and both `gama`\n",
        "    and `beta` will not be updated !\n",
        "    \"\"\"\n",
        "    def call(self, x, training=False):\n",
        "        if not training:\n",
        "            training = tf.constant(False)\n",
        "        training = tf.logical_and(training, self.trainable)\n",
        "        return super().call(x, training)\n",
        "\n",
        "def convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True):\n",
        "    if downsample:\n",
        "        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
        "        padding = 'valid'\n",
        "        strides = 2\n",
        "    else:\n",
        "        strides = 1\n",
        "        padding = 'same'\n",
        "\n",
        "    conv = tf.keras.layers.Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides, padding=padding,\n",
        "                                  use_bias=not bn, kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n",
        "                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
        "                                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n",
        "\n",
        "    if bn: conv = BatchNormalization()(conv)\n",
        "    if activate == True: conv = tf.nn.leaky_relu(conv, alpha=0.1)\n",
        "\n",
        "    return conv\n",
        "\n",
        "def residual_block(input_layer, input_channel, filter_num1, filter_num2):\n",
        "    short_cut = input_layer\n",
        "    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1))\n",
        "    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2))\n",
        "\n",
        "    residual_output = short_cut + conv\n",
        "    return residual_output\n",
        "\n",
        "def upsample(input_layer):\n",
        "    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='nearest')"
      ],
      "metadata": {
        "id": "R9oumNivOgwh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#core-utils\n",
        "#! /usr/bin/env python\n",
        "# coding=utf-8\n",
        "#================================================================\n",
        "#   Copyright (C) 2019 * Ltd. All rights reserved.\n",
        "#\n",
        "#   Editor      : VIM\n",
        "#   File name   : utils.py\n",
        "#   Author      : YunYang1994\n",
        "#   Created date: 2019-07-12 01:33:38\n",
        "#   Description :\n",
        "#\n",
        "#================================================================\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import colorsys\n",
        "import numpy as np\n",
        "# from core.config import cfg\n",
        "\n",
        "def load_weights(model, weights_file):\n",
        "    \"\"\"\n",
        "    I agree that this code is very ugly, but I donâ€™t know any better way of doing it.\n",
        "    \"\"\"\n",
        "    wf = open(weights_file, 'rb')\n",
        "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
        "\n",
        "    j = 0\n",
        "    for i in range(75):\n",
        "        conv_layer_name = 'conv2d_%d' %i if i > 0 else 'conv2d'\n",
        "        bn_layer_name = 'batch_normalization_%d' %j if j > 0 else 'batch_normalization'\n",
        "\n",
        "        conv_layer = model.get_layer(conv_layer_name)\n",
        "        filters = conv_layer.filters\n",
        "        k_size = conv_layer.kernel_size[0]\n",
        "        in_dim = conv_layer.input_shape[-1]\n",
        "\n",
        "        if i not in [58, 66, 74]:\n",
        "            # darknet weights: [beta, gamma, mean, variance]\n",
        "            bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n",
        "            # tf weights: [gamma, beta, mean, variance]\n",
        "            bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
        "            bn_layer = model.get_layer(bn_layer_name)\n",
        "            j += 1\n",
        "        else:\n",
        "            conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
        "\n",
        "        # darknet shape (out_dim, in_dim, height, width)\n",
        "        conv_shape = (filters, in_dim, k_size, k_size)\n",
        "        conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
        "        # tf shape (height, width, in_dim, out_dim)\n",
        "        conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
        "\n",
        "        if i not in [58, 66, 74]:\n",
        "            conv_layer.set_weights([conv_weights])\n",
        "            bn_layer.set_weights(bn_weights)\n",
        "        else:\n",
        "            conv_layer.set_weights([conv_weights, conv_bias])\n",
        "\n",
        "    assert len(wf.read()) == 0, 'failed to read all data'\n",
        "    wf.close()\n",
        "\n",
        "\n",
        "def read_class_names(class_file_name):\n",
        "    '''loads class name from a file'''\n",
        "    names = {}\n",
        "    with open(class_file_name, 'r') as data:\n",
        "        for ID, name in enumerate(data):\n",
        "            names[ID] = name.strip('\\n')\n",
        "    return names\n",
        "\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = np.array(anchors.split(','), dtype=np.float32)\n",
        "    return anchors.reshape(3, 3, 2)\n",
        "\n",
        "\n",
        "def image_preporcess(image, target_size, gt_boxes=None):\n",
        "\n",
        "    ih, iw    = target_size\n",
        "    h,  w, _  = image.shape\n",
        "\n",
        "    scale = min(iw/w, ih/h)\n",
        "    nw, nh  = int(scale * w), int(scale * h)\n",
        "    image_resized = cv2.resize(image, (nw, nh))\n",
        "\n",
        "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
        "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
        "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
        "    image_paded = image_paded / 255.\n",
        "\n",
        "    if gt_boxes is None:\n",
        "        return image_paded\n",
        "\n",
        "    else:\n",
        "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
        "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
        "        return image_paded, gt_boxes\n",
        "\n",
        "\n",
        "def draw_bbox(image, bboxes, classes=read_class_names(FLAGS.classes), show_label=True):\n",
        "    \"\"\"\n",
        "    bboxes: [x_min, y_min, x_max, y_max, probability, cls_id] format coordinates.\n",
        "    \"\"\"\n",
        "\n",
        "    num_classes = len(classes)\n",
        "    image_h, image_w, _ = image.shape\n",
        "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
        "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
        "\n",
        "    random.seed(0)\n",
        "    random.shuffle(colors)\n",
        "    random.seed(None)\n",
        "\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        coor = np.array(bbox[:4], dtype=np.int32)\n",
        "        fontScale = 0.5\n",
        "        score = bbox[4]\n",
        "        class_ind = int(bbox[5])\n",
        "        bbox_color = colors[class_ind]\n",
        "        bbox_thick = int(0.6 * (image_h + image_w) / 600)\n",
        "        c1, c2 = (coor[0], coor[1]), (coor[2], coor[3])\n",
        "        cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n",
        "\n",
        "        if show_label:\n",
        "            bbox_mess = '%s: %.2f' % (classes[class_ind], score)\n",
        "            t_size = cv2.getTextSize(bbox_mess, 0, fontScale, thickness=bbox_thick//2)[0]\n",
        "            cv2.rectangle(image, c1, (c1[0] + t_size[0], c1[1] - t_size[1] - 3), bbox_color, -1)  # filled\n",
        "\n",
        "            cv2.putText(image, bbox_mess, (c1[0], c1[1]-2), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        fontScale, (0, 0, 0), bbox_thick//2, lineType=cv2.LINE_AA)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "def bboxes_iou(boxes1, boxes2):\n",
        "\n",
        "    boxes1 = np.array(boxes1)\n",
        "    boxes2 = np.array(boxes2)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
        "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area    = boxes1_area + boxes2_area - inter_area\n",
        "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
        "\n",
        "    return ious\n",
        "\n",
        "\n",
        "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
        "    \"\"\"\n",
        "    :param bboxes: (xmin, ymin, xmax, ymax, score, class)\n",
        "    Note: soft-nms, https://arxiv.org/pdf/1704.04503.pdf\n",
        "          https://github.com/bharatsingh430/soft-nms\n",
        "    \"\"\"\n",
        "    classes_in_img = list(set(bboxes[:, 5]))\n",
        "    best_bboxes = []\n",
        "\n",
        "    for cls in classes_in_img:\n",
        "        cls_mask = (bboxes[:, 5] == cls)\n",
        "        cls_bboxes = bboxes[cls_mask]\n",
        "\n",
        "        while len(cls_bboxes) > 0:\n",
        "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
        "            best_bbox = cls_bboxes[max_ind]\n",
        "            best_bboxes.append(best_bbox)\n",
        "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
        "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
        "            weight = np.ones((len(iou),), dtype=np.float32)\n",
        "\n",
        "            assert method in ['nms', 'soft-nms']\n",
        "\n",
        "            if method == 'nms':\n",
        "                iou_mask = iou > iou_threshold\n",
        "                weight[iou_mask] = 0.0\n",
        "\n",
        "            if method == 'soft-nms':\n",
        "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
        "\n",
        "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
        "            score_mask = cls_bboxes[:, 4] > 0.\n",
        "            cls_bboxes = cls_bboxes[score_mask]\n",
        "\n",
        "    return best_bboxes\n",
        "\n",
        "\n",
        "def postprocess_boxes(pred_bbox, org_img_shape, input_size, score_threshold):\n",
        "\n",
        "    valid_scale=[0, np.inf]\n",
        "    pred_bbox = np.array(pred_bbox)\n",
        "\n",
        "    pred_xywh = pred_bbox[:, 0:4]\n",
        "    pred_conf = pred_bbox[:, 4]\n",
        "    pred_prob = pred_bbox[:, 5:]\n",
        "\n",
        "    # # (1) (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
        "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
        "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
        "    # # (2) (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
        "    org_h, org_w = org_img_shape\n",
        "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
        "\n",
        "    dw = (input_size - resize_ratio * org_w) / 2\n",
        "    dh = (input_size - resize_ratio * org_h) / 2\n",
        "\n",
        "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
        "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
        "\n",
        "    # # (3) clip some boxes those are out of range\n",
        "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
        "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
        "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
        "    pred_coor[invalid_mask] = 0\n",
        "\n",
        "    # # (4) discard some invalid boxes\n",
        "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
        "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
        "\n",
        "    # # (5) discard some boxes with low scores\n",
        "    classes = np.argmax(pred_prob, axis=-1)\n",
        "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
        "    score_mask = scores > score_threshold\n",
        "    mask = np.logical_and(scale_mask, score_mask)\n",
        "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
        "\n",
        "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "jpJ7-w6rOVeA",
        "outputId": "a5531671-e3d0-47c6-80ec-2ff07db303fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7556918cc8ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_class_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYOLO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m    106\u001b[0m     \u001b[0mbboxes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mformat\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-7556918cc8ef>\u001b[0m in \u001b[0;36mread_class_names\u001b[0;34m(class_file_name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m'''loads class name from a file'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_file_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/classes/coco.names'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#core-yolov3\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# import core.utils as utils\n",
        "# import core.common as common\n",
        "# import core.backbone as backbone\n",
        "# from core.config import cfg\n",
        "\n",
        "\n",
        "NUM_CLASS       = len(utils.read_class_names(FLAGS.classes))\n",
        "ANCHORS         = utils.get_anchors(FLAGS.anchors)\n",
        "STRIDES         = np.array(FLAGS.strides)\n",
        "IOU_LOSS_THRESH = cfg.YOLO.IOU_LOSS_THRESH\n",
        "\n",
        "def YOLOv3(input_layer):\n",
        "    route_1, route_2, conv = backbone.darknet53(input_layer)\n",
        "\n",
        "    conv = common.convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = common.convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = common.convolutional(conv, (1, 1, 1024,  512))\n",
        "    conv = common.convolutional(conv, (3, 3,  512, 1024))\n",
        "    conv = common.convolutional(conv, (1, 1, 1024,  512))\n",
        "\n",
        "    conv_lobj_branch = common.convolutional(conv, (3, 3, 512, 1024))\n",
        "    conv_lbbox = common.convolutional(conv_lobj_branch, (1, 1, 1024, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = common.convolutional(conv, (1, 1,  512,  256))\n",
        "    conv = common.upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_2], axis=-1)\n",
        "\n",
        "    conv = common.convolutional(conv, (1, 1, 768, 256))\n",
        "    conv = common.convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = common.convolutional(conv, (1, 1, 512, 256))\n",
        "    conv = common.convolutional(conv, (3, 3, 256, 512))\n",
        "    conv = common.convolutional(conv, (1, 1, 512, 256))\n",
        "\n",
        "    conv_mobj_branch = common.convolutional(conv, (3, 3, 256, 512))\n",
        "    conv_mbbox = common.convolutional(conv_mobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
        "\n",
        "    conv = common.convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = common.upsample(conv)\n",
        "\n",
        "    conv = tf.concat([conv, route_1], axis=-1)\n",
        "\n",
        "    conv = common.convolutional(conv, (1, 1, 384, 128))\n",
        "    conv = common.convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = common.convolutional(conv, (1, 1, 256, 128))\n",
        "    conv = common.convolutional(conv, (3, 3, 128, 256))\n",
        "    conv = common.convolutional(conv, (1, 1, 256, 128))\n",
        "\n",
        "    conv_sobj_branch = common.convolutional(conv, (3, 3, 128, 256))\n",
        "    conv_sbbox = common.convolutional(conv_sobj_branch, (1, 1, 256, 3*(NUM_CLASS +5)), activate=False, bn=False)\n",
        "\n",
        "    return [conv_sbbox, conv_mbbox, conv_lbbox]\n",
        "\n",
        "def decode(conv_output, i=0):\n",
        "    \"\"\"\n",
        "    return tensor of shape [batch_size, output_size, output_size, anchor_per_scale, 5 + num_classes]\n",
        "            contains (x, y, w, h, score, probability)\n",
        "    \"\"\"\n",
        "\n",
        "    conv_shape       = tf.shape(conv_output)\n",
        "    batch_size       = conv_shape[0]\n",
        "    output_size      = conv_shape[1]\n",
        "\n",
        "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2]\n",
        "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4]\n",
        "    conv_raw_conf = conv_output[:, :, :, :, 4:5]\n",
        "    conv_raw_prob = conv_output[:, :, :, :, 5: ]\n",
        "\n",
        "    y = tf.tile(tf.range(output_size, dtype=tf.int32)[:, tf.newaxis], [1, output_size])\n",
        "    x = tf.tile(tf.range(output_size, dtype=tf.int32)[tf.newaxis, :], [output_size, 1])\n",
        "\n",
        "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
        "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
        "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
        "\n",
        "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
        "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
        "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
        "\n",
        "    pred_conf = tf.sigmoid(conv_raw_conf)\n",
        "    pred_prob = tf.sigmoid(conv_raw_prob)\n",
        "\n",
        "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
        "\n",
        "def bbox_iou(boxes1, boxes2):\n",
        "\n",
        "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
        "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
        "\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "\n",
        "    return 1.0 * inter_area / union_area\n",
        "\n",
        "def bbox_giou(boxes1, boxes2):\n",
        "\n",
        "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
        "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
        "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
        "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
        "\n",
        "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
        "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
        "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
        "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
        "\n",
        "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
        "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
        "\n",
        "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
        "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "\n",
        "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
        "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
        "    union_area = boxes1_area + boxes2_area - inter_area\n",
        "    iou = inter_area / union_area\n",
        "\n",
        "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
        "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
        "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
        "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
        "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
        "\n",
        "    return giou\n",
        "\n",
        "\n",
        "def compute_loss(pred, conv, label, bboxes, i=0):\n",
        "\n",
        "    conv_shape  = tf.shape(conv)\n",
        "    batch_size  = conv_shape[0]\n",
        "    output_size = conv_shape[1]\n",
        "    input_size  = STRIDES[i] * output_size\n",
        "    conv = tf.reshape(conv, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
        "\n",
        "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
        "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
        "\n",
        "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
        "    pred_conf     = pred[:, :, :, :, 4:5]\n",
        "\n",
        "    label_xywh    = label[:, :, :, :, 0:4]\n",
        "    respond_bbox  = label[:, :, :, :, 4:5]\n",
        "    label_prob    = label[:, :, :, :, 5:]\n",
        "\n",
        "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)\n",
        "    input_size = tf.cast(input_size, tf.float32)\n",
        "\n",
        "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
        "    giou_loss = respond_bbox * bbox_loss_scale * (1- giou)\n",
        "\n",
        "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :], bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :])\n",
        "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)\n",
        "\n",
        "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < IOU_LOSS_THRESH, tf.float32 )\n",
        "\n",
        "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
        "\n",
        "    conf_loss = conf_focal * (\n",
        "            respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "            +\n",
        "            respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
        "    )\n",
        "\n",
        "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n",
        "\n",
        "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4]))\n",
        "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4]))\n",
        "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4]))\n",
        "\n",
        "    return giou_loss, conf_loss, prob_loss"
      ],
      "metadata": {
        "id": "zl0bvV4UOGjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxMggpH4Nedm"
      },
      "outputs": [],
      "source": [
        "#train\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# import core.utils as utils\n",
        "from tqdm import tqdm\n",
        "# from core.dataset import Dataset\n",
        "# from core.yolov3 import YOLOv3, decode, compute_loss\n",
        "# from core.config import cfg\n",
        "\n",
        "trainset = Dataset('train')\n",
        "logdir = \"./data/log\"\n",
        "steps_per_epoch = len(trainset)\n",
        "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
        "warmup_steps = cfg.TRAIN.WARMUP_EPOCHS * steps_per_epoch\n",
        "total_steps = cfg.TRAIN.EPOCHS * steps_per_epoch\n",
        "\n",
        "input_tensor = tf.keras.layers.Input([416, 416, 3])\n",
        "conv_tensors = YOLOv3(input_tensor)\n",
        "\n",
        "output_tensors = []\n",
        "for i, conv_tensor in enumerate(conv_tensors):\n",
        "    pred_tensor = decode(conv_tensor, i)\n",
        "    output_tensors.append(conv_tensor)\n",
        "    output_tensors.append(pred_tensor)\n",
        "\n",
        "model = tf.keras.Model(input_tensor, output_tensors)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "if os.path.exists(logdir): shutil.rmtree(logdir)\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "def train_step(image_data, target):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred_result = model(image_data, training=True)\n",
        "        giou_loss=conf_loss=prob_loss=0\n",
        "\n",
        "        # optimizing process\n",
        "        for i in range(3):\n",
        "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
        "            loss_items = compute_loss(pred, conv, *target[i], i)\n",
        "            giou_loss += loss_items[0]\n",
        "            conf_loss += loss_items[1]\n",
        "            prob_loss += loss_items[2]\n",
        "\n",
        "        total_loss = giou_loss + conf_loss + prob_loss\n",
        "\n",
        "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        tf.print(\"=> STEP %4d   lr: %.6f   giou_loss: %4.2f   conf_loss: %4.2f   \"\n",
        "                 \"prob_loss: %4.2f   total_loss: %4.2f\" %(global_steps, optimizer.lr.numpy(),\n",
        "                                                          giou_loss, conf_loss,\n",
        "                                                          prob_loss, total_loss))\n",
        "        # update learning rate\n",
        "        global_steps.assign_add(1)\n",
        "        if global_steps < warmup_steps:\n",
        "            lr = global_steps / warmup_steps *cfg.TRAIN.LR_INIT\n",
        "        else:\n",
        "            lr = cfg.TRAIN.LR_END + 0.5 * (cfg.TRAIN.LR_INIT - cfg.TRAIN.LR_END) * (\n",
        "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi))\n",
        "            )\n",
        "        optimizer.lr.assign(lr.numpy())\n",
        "\n",
        "        # writing summary data\n",
        "        with writer.as_default():\n",
        "            tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
        "            tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
        "            tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
        "            tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
        "            tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
        "        writer.flush()\n",
        "\n",
        "\n",
        "for epoch in range(cfg.TRAIN.EPOCHS):\n",
        "    for image_data, target in trainset:\n",
        "        train_step(image_data, target)\n",
        "    model.save_weights(\"./yolov3\")"
      ]
    }
  ]
}