{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6889e01",
   "metadata": {},
   "source": [
    "# Optimizers Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46196cda",
   "metadata": {},
   "source": [
    "# Simple Demo 1D SGD with animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d288e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1552/420900260.py:53: UserWarning: marker is redundantly defined by the 'marker' keyword argument and the fmt string \"r.\" (-> marker='.'). The keyword argument will take precedence.\n",
      "  p2, = ax.plot([], [],  'r.', marker='.', alpha=.5)\n",
      "/tmp/ipykernel_1552/420900260.py:55: UserWarning: marker is redundantly defined by the 'marker' keyword argument and the fmt string \"r.\" (-> marker='.'). The keyword argument will take precedence.\n",
      "  p3, = ax.plot([], [],  'r.', marker='.', alpha=.5, ms=10)\n",
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def animate_optimizer(frame, opt, loss, lossf, x_sgd, x_cord_list, p2, p3):\n",
    "    step_count = opt.minimize(loss, var_list=[x_sgd]).numpy()\n",
    "    p3.set_data(x_sgd.numpy(), lossf(x_sgd.numpy()))\n",
    "    x_cord_list.append(x_sgd.numpy() )\n",
    "    loss_y = [lossf(xt) for xt in x_cord_list]\n",
    "    p2.set_data(x_cord_list, loss_y)\n",
    "    return p2, p3, x_sgd,\n",
    "\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "\n",
    "lossf = lambda x: (x ** 2)/2.0     \n",
    "\n",
    "x=list(np.linspace(-6, 6.0, 100))\n",
    "y = []\n",
    "for x_cord_list in x:\n",
    "    y.append(lossf(x_cord_list))\n",
    "\n",
    "x_cord_list = []\n",
    "\n",
    "plt.clf\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel('w1')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Gradient Descent')\n",
    "\n",
    "## 1d 1single weight loss plot\n",
    "\n",
    "x_sgd = tf.Variable(5.0)\n",
    "p1, = ax.plot([x_sgd], [lossf(x_sgd)], 'k')\n",
    "p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "p2, = ax.plot([], [],  'r.', marker='.', alpha=.5)\n",
    "\n",
    "p3, = ax.plot([], [],  'r.', marker='.', alpha=.5, ms=10)\n",
    "max_iter = 100\n",
    "loss = lambda: (x_sgd ** 2)/2.0      \n",
    "\n",
    "\n",
    "anim2 = animation.FuncAnimation(fig, animate_optimizer, \n",
    "                                frames=range(0, max_iter),  fargs = (opt, loss, lossf, x_sgd, x_cord_list, p2, p3), interval=50,repeat=True, repeat_delay=20)\n",
    "filename = 'sgd_1d_intro.gif'\n",
    "\n",
    "anim2\n",
    "anim2.save(filename, dpi=80, writer='imagemagick', fps=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb539b",
   "metadata": {},
   "source": [
    "# Optimizers Graph Generation - Loops on optimizers list, and generates 3d animations with various elevations, and 2D contour animation per each optimizer. All outputs are saved to gif files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2829a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 09:24:17.375786: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d6562e3b3147b2886cca1495ee7ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddcd42aec814827bf02492c5a2cc697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a30441c8cf84e68a963ea5bc890c39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    }
   ],
   "source": [
    "# Optimizers Graph Generation - Loops on aoptimizers list, and generate 3d animations with various elevations and 2D contour animation per each optimizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "# from mpl_toolkits.mplot3d import axes3d, Axes3D #<-- Note the capitalization! \n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "####### #3D anaimate and contour plot\n",
    "\n",
    "def animate_optimizer_3d(frame, opt, loss_func, loss_func_args, x_cord, y_cord, x_cord_list, yy, zz, ax, p2, p3):  \n",
    "    step_count = opt.minimize(loss_func, var_list=[y_cord, x_cord]).numpy()\n",
    "    ax.title.set_text('3D Plot, Frame={}'.format(frame))\n",
    "    p3.set_data(x_cord.numpy(), y_cord.numpy())\n",
    "    p3.set_3d_properties(loss_func_args(x_cord.numpy(), y_cord.numpy())) \n",
    "    p2.set_data(np.array(x_cord_list), np.array(yy))\n",
    "    p2.set_3d_properties(np.array(zz)) \n",
    "    x_cord_list.append(x_cord.numpy())\n",
    "    yy.append(y_cord.numpy())\n",
    "    zz.append(loss_func_args(x_cord.numpy(), y_cord.numpy())) \n",
    "    return p3, x_cord, y_cord\n",
    "\n",
    "\n",
    "def plot_loss_func_3d(loss_func_args):\n",
    "    x_cord_list = np.linspace(-5.5, 5.5, 100)\n",
    "    yy = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x_cord_list, yy)\n",
    "    Z = loss_func_args(X, Y)\n",
    "    fig1 = plt.figure(figsize=(16, 6))\n",
    "    fig1.set_figheight(10)\n",
    "    fig1.set_figwidth(10)\n",
    "    ax1 = plt.axes(projection='3d')\n",
    "    surf = ax1.plot_surface(X, Y, Z, rstride=1, cstride=1, alpha=0.3, \n",
    "                           linewidth=0, antialiased=False)\n",
    "    ax1.set_xlabel('w1', fontsize=20)\n",
    "    ax1.set_ylabel('w2', fontsize=20)\n",
    "    ax1.set_zlabel('J(w1, w2)', fontsize=20)\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "    ax1.zaxis.set_ticklabels([])\n",
    "    return fig1, ax1\n",
    "\n",
    "\n",
    "####### #3D anaimate and contour plot\n",
    "\n",
    "def animate_contour_2d(frame, opt, loss_func, \n",
    "                       loss_func_args, \n",
    "                       x_cord, y_cord, x_cord_list, yy, ax, \n",
    "                       p2, p3):   \n",
    "\n",
    "    step_count = opt.minimize(loss_func, var_list=[y_cord, x_cord]).numpy()\n",
    "    ax.title.set_text('2D Contour Plot, Frame={}'.format(frame))\n",
    "    if step_count > -10:\n",
    "        p3.set_data([x_cord.numpy()], [y_cord.numpy()])\n",
    "\n",
    "        p2.set_data(np.array(x_cord_list), np.array(yy))\n",
    "\n",
    "        x_cord_list.append(x_cord.numpy())\n",
    "        yy.append(y_cord.numpy())\n",
    "\n",
    "    return p3, x_cord, y_cord\n",
    "\n",
    "def plot_contour(loss_with_args):\n",
    "    x = np.linspace(-5.5, 5.5, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    return fig,ax\n",
    "\n",
    "\n",
    "# Configurations\n",
    "alpha=learning_rate = 0.1 \n",
    "\n",
    "\n",
    "# Set loss func\n",
    "y_coeff_moderate = 15\n",
    "y_coeff = 20\n",
    "x_coeff = 1\n",
    "loss_func_args_symetric = lambda x_cord, y_cord: (x_cord ** 2)/2.0  + (y_cord ** 2)/2.0 \n",
    "loss_func_symetric = lambda: (x_cord ** 2)/2.0  + (y_cord ** 2)/2.0\n",
    "\n",
    "loss_func_args_asymetric_stable  = lambda x_cord, y_cord: x_coeff * (x_cord ** 2)/2.0  + y_coeff_moderate*(y_cord ** 2)/2.0 \n",
    "loss_func_asymetric_stable = lambda: x_coeff * (x_cord ** 2)/2.0  + y_coeff_moderate*(y_cord ** 2)/2.0\n",
    "\n",
    "loss_func_args_y_steep = lambda x_cord, y_cord: x_coeff * (x_cord ** 2)/2.0  + y_coeff*(y_cord ** 2)/2.0 \n",
    "loss_func_y_steep = lambda: x_coeff * (x_cord ** 2)/2.0  + y_coeff*(y_cord ** 2)/2.0\n",
    "\n",
    "# Set desired iteration: filenames and elevetion, e.g. provide various eleveation views\n",
    "algorythms_list = [\n",
    "\n",
    "    {\n",
    "        'name': 'sgd',\n",
    "        'num_of_iter': 10,\n",
    "        'opt': tf.keras.optimizers.SGD(learning_rate=alpha), \n",
    "        'plot_3d': True,\n",
    "    },\n",
    "    {\n",
    "        'name': 'momentum_sgd',\n",
    "        'num_of_iter': 100,\n",
    "        'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9, nesterov=False), \n",
    "        'plot_3d': True\n",
    "     },\n",
    "\n",
    "    {\n",
    "        'name': 'nesterov_sgd',\n",
    "        'num_of_iter': 100,\n",
    "        'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9, nesterov=True), \n",
    "        'plot_3d': True\n",
    "    },\n",
    "       {\n",
    "        'name': 'adagrad',\n",
    "        'opt': tf.keras.optimizers.Adagrad(learning_rate=alpha,initial_accumulator_value=0.1,epsilon=1e-07,name=\"Adagrad\"),\n",
    "        'num_of_iter': 180,\n",
    "        'plot_3d': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'rmsprop',\n",
    "        'opt': tf.keras.optimizers.RMSprop(learning_rate=alpha, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False, name=\"RMSprop\"),\n",
    "        'num_of_iter': 80,\n",
    "        'plot_3d': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'adadelta',\n",
    "        'opt': tf.keras.optimizers.Adadelta(learning_rate=alpha, rho=0.95, epsilon=1e-07, name=\"Adadelta\"),\n",
    "        'num_of_iter': 80,\n",
    "        'plot_3d': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'adam',\n",
    "        'num_of_iter': 120,\n",
    "        'opt': tf.keras.optimizers.Adam(learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam'),\n",
    "        'plot_3d': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'adamax'\n",
    "        'num_of_iter': 150,\n",
    "        'opt': tf.keras.optimizers.Adamax(learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,name='Adamax'), \n",
    "        'plot_3d': True\n",
    "    },\n",
    "    {\n",
    "        'name': 'nadam',\n",
    "        'opt': tf.keras.optimizers.Nadam(learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\"),\n",
    "        'num_of_iter': 120,\n",
    "        'plot_3d': True\n",
    "    },\n",
    "\n",
    "     ]\n",
    "\n",
    "loss_funcs_list =  [ {\n",
    "        'name': 'converge',\n",
    "        'loss_func_args': loss_func_args_symetric, \n",
    "        'loss_func': loss_func_symetric\n",
    "    },\n",
    "    {\n",
    "        'name': 'stable',\n",
    "        'loss_func_args': loss_func_args_asymetric_stable, \n",
    "        'loss_func':loss_func_asymetric_stable\n",
    "    }, \n",
    "\n",
    "    {\n",
    "        'name': 'steep',\n",
    "        'loss_func_args': loss_func_args_y_steep , \n",
    "        'loss_func': loss_func_y_steep\n",
    "    }\n",
    "]\n",
    "       \n",
    "camera_positions = [{'elev': 0, 'azim': 0}, {'elev': 0, 'azim': 30}, {'elev': 90, 'azim': 30}]\n",
    "\n",
    "default_num_of_iter = 20\n",
    "# Main loop, runs on various algorithms\n",
    "for algorithm in algorythms_list:\n",
    "    max_iter = algorithm.get('num_of_iter', default_num_of_iter)\n",
    "    opt = algorithm['opt']\n",
    "    alg_name = algorithm['name']\n",
    "    # loop on loss functions\n",
    "    for loss_funcs in loss_funcs_list: \n",
    "        test_name = loss_funcs['name']\n",
    "\n",
    "        loss_func_args = loss_funcs['loss_func_args']\n",
    "        loss_func = loss_funcs['loss_func']\n",
    "\n",
    "        ## Now plot 2d contour\n",
    "        x_cord = tf.Variable(5.0)\n",
    "        y_cord = tf.Variable(5.0)\n",
    "        x_cord_list = []\n",
    "        yy = []\n",
    "        filename = '2d_contour_' + alg_name + '_' + test_name +'.gif'\n",
    "\n",
    "        fig_contour, ax_contour = plot_contour(loss_func_args)\n",
    "\n",
    "        ax_contour.plot(x_cord, x_cord, \"x-\", color='red', alpha=0.6)\n",
    "        p2_contour, = ax_contour.plot([], [], \".-\", color='red', alpha=0.6)\n",
    "        p3_contour, = ax_contour.plot([], [], \"o-\", color='blue', alpha=0.6)\n",
    "        ax_contour.set_xlabel('w1')\n",
    "        ax_contour.set_ylabel('w2')\n",
    "        ax_contour.set_yticklabels([])\n",
    "        ax_contour.set_xticklabels([])\n",
    "        ax_contour.set_title('Optimization using {name} - Contour Plot'.format(name=filename))\n",
    "        anim2 = animation.FuncAnimation(fig_contour, animate_contour_2d, frames=range(0, max_iter), fargs=(opt, loss_func, loss_func_args, x_cord, y_cord, x_cord_list, yy, ax_contour, p2_contour, p3_contour), interval=30,repeat=True, repeat_delay=20)\n",
    "        anim2.save('output/'+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "\n",
    "\n",
    "        # Internal loop, relevant to 3D contour: camera positions\n",
    "        \n",
    "        if not algorithm.get('plot_3d'):\n",
    "            continue\n",
    "            \n",
    "        for camera_position in camera_positions:\n",
    "           \n",
    "            x_cord = tf.Variable(5.0)\n",
    "            y_cord = tf.Variable(5.0)\n",
    "            x_cord_list = []\n",
    "            yy = []\n",
    "            zz = []\n",
    "\n",
    "            azim = camera_position['azim']\n",
    "            elev = camera_position['elev']\n",
    "            plt.clf\n",
    "            # plot loss func as a background:\n",
    "      \n",
    "            fig, ax = plot_loss_func_3d(loss_func_args)\n",
    "\n",
    "            title = ax.set_title('3D View')\n",
    "\n",
    "            z = loss_func_args(x_cord.numpy(), y_cord.numpy())\n",
    "            p3, = ax.plot(x_cord.numpy(), y_cord.numpy(), z,  'bo')\n",
    "            p2, = ax.plot(np.array([x_cord.numpy()]), np.array([y_cord.numpy()]), np.array([z]), 'r.-')\n",
    "            if camera_position:\n",
    "                ax.view_init(azim=camera_position['azim'], elev=camera_position['elev'])\n",
    "            filename = '3d_contour_'  + alg_name + '_' + test_name\n",
    "            if elev not in [None, 'Default']:\n",
    "                filename = filename + '_azim_' + str(azim) +  '_elev_' + str(elev)\n",
    "            filename = filename + '.gif'\n",
    "\n",
    "            anim1 = animation.FuncAnimation(fig, animate_optimizer_3d, frames=range(0, max_iter),\n",
    "                                            fargs=(opt, loss_func, loss_func_args, x_cord, y_cord, x_cord_list, yy, zz, ax, p2, p3), blit=True, interval=30,repeat=True, repeat_delay=20)\n",
    "            anim1.save('output/'+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2651054",
   "metadata": {},
   "source": [
    "# SGD and momentum together - no animation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e610e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using widget instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1d67ac68ae4dadafc3ec84c569bf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e056c53b754ceea5908f014e637e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4572c52eb48543df83ecf240d69f31d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e101d630fa474d8ebc5d4179255888ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbd56390beb4065953c8494c07482d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95485b94a1b042d0b4326b8855dd830b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradeint Descent with large step size with animation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# %matplotlib widget\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "X_COEF=1\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "x_offset = 2\n",
    "y_offset = 1.5\n",
    "\n",
    "\n",
    "loss_with_args = lambda x_cord, y_cord: X_COEF*(x_cord)**2 + Y_COEF*(y_cord)**2         # d(loss)/d(var1) = var1\n",
    "loss = lambda: X_COEF*(x_cord)**2 + Y_COEF*(y_cord)**2         # d(loss)/d(var1) = var1\n",
    "\n",
    "\n",
    "def plot_contour():\n",
    "    x = np.linspace(-5.5, 5.5, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    return fig,ax\n",
    "\n",
    "\n",
    "\n",
    "def do_optimize(opt, num_iterations, name):\n",
    "    loss = lambda: X_COEF*(x_cord)**2 + Y_COEF*(y_cord)**2         # d(loss)/d(var1) = var1\n",
    "\n",
    "    fig, ax = plot_contour()\n",
    "    x_cord = tf.Variable(-5.0)\n",
    "    y_cord = tf.Variable(-2.0)\n",
    "    x_cord_list = []\n",
    "    yy = []\n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss, var_list=[x_cord, y_cord]).numpy()\n",
    "        x_cord_list.append(x_cord.numpy())\n",
    "        yy.append(y_cord.numpy())\n",
    "\n",
    "    ax.plot(x_cord_list, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "\n",
    "\n",
    "# SGD\n",
    "num_iterations = 100\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=alpha)\n",
    "do_optimize(opt, num_iterations, name = \"SGD\")\n",
    "\n",
    "# Momentum\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9)\n",
    "do_optimize(opt, num_iterations, name = \"Momentum\")\n",
    "\n",
    "# ADADELTA\n",
    "num_iterations = 100\n",
    "\n",
    "opt = tf.keras.optimizers.Adadelta(learning_rate=5, rho=0.95, epsilon=1e-07, name=\"Adadelta\")\n",
    "opt = keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07, name=\"Adadelta\")\n",
    "do_optimize(opt, num_iterations, name = \"ADADELTA\")\n",
    "\n",
    "\n",
    "# ADAM\n",
    "num_iterations = 150\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'\n",
    ")\n",
    "\n",
    "opt = do_optimize(opt, num_iterations, name = \"Adam\")\n",
    "\n",
    "\n",
    "# ADAMAX\n",
    "\n",
    "opt = tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'\n",
    ")\n",
    "\n",
    "\n",
    "do_optimize(opt, num_iterations, name = \"Adamax\")\n",
    "\n",
    "\n",
    "# var1 = tf.Variable(10.0)\n",
    "# loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
    "# step_count = opt.minimize(loss, [var1]).numpy()\n",
    "# The first step is `-learning_rate*sign(grad)`\n",
    "# var1.numpy()\n",
    "\n",
    "# opimize(opt, ax)\n",
    "\n",
    "# Adagrad\n",
    "num_iterations=600\n",
    "opt = tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=alpha, initial_accumulator_value=0.1, epsilon=1e-07,\n",
    "    name='Adagrad'\n",
    ")\n",
    "do_optimize(opt, num_iterations, name = \"Adagrad\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5d2a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933cf78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17872dd8",
   "metadata": {},
   "source": [
    "# Optimizers with contours - Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "X_COEF=1\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "x_offset = 2\n",
    "y_offset = 1.5\n",
    "\n",
    "\n",
    "\n",
    "def plot_contour(loss_with_args, title):\n",
    "\n",
    "    x = np.linspace(-5.5, 5.5, 100)\n",
    "    y = np.linspace(-5.5, 5.5, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    levels = [0.1,1,2,4,9, 16, 25, 36, 49, 64, 81, 100, 121, 144,169, 196, 225, 256, 289]\n",
    "    Z = loss_with_args(X,Y)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.contour(X, Y, Z, levels, colors='black')\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel('w1')\n",
    "    ax.set_ylabel('b')\n",
    "\n",
    "    ax.set_title(title)\n",
    "    return fig,ax\n",
    "\n",
    "def init_animate_optimizer():\n",
    "    global xs\n",
    "    global x_cord\n",
    "    global y_cord\n",
    "    global opt\n",
    "    global x_cord_list\n",
    "    global yy\n",
    "    \n",
    "\n",
    "    x_cord = tf.Variable(-5.0)\n",
    "    y_cord = tf.Variable(-2.0)\n",
    "    x_cord_list = []\n",
    "    yy = []\n",
    "    return p1,\n",
    "\n",
    "\n",
    "\n",
    "x_cord_list = []\n",
    "yy = []\n",
    "def animate_optimizer(frame, opt, loss_func):\n",
    "    global x\n",
    "    global x_cord\n",
    "    global y_cord\n",
    "    global x_cord_list\n",
    "    global yy\n",
    "    global p2, p3\n",
    "   \n",
    "    step_count = opt.minimize(loss_func, var_list=[x_cord, y_cord]).numpy()\n",
    "\n",
    "    p2.set_data(x_cord_list, yy)\n",
    "    p3.set_data(x_cord.numpy(), y_cord.numpy())\n",
    "    x_cord_list.append(x_cord.numpy())\n",
    "    yy.append(y_cord.numpy())\n",
    "    return p2,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed6409",
   "metadata": {},
   "source": [
    "# Run optimizations - static plots with loss_diff_in_gradients - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bade39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "def do_optimize(loss_with_args, opt, num_iterations, name):\n",
    "\n",
    "\n",
    "    fig, ax = plot_contour(loss_with_args, name)\n",
    "\n",
    "    x_cord_list = []\n",
    "    yy = []\n",
    "    \n",
    "    x_cord = tf.Variable(-5.0)\n",
    "    y_cord = tf.Variable(-2.0)\n",
    "    loss_func = lambda: 1*(x_cord)**2 + 40*(y_cord)**2  \n",
    "\n",
    "\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[x_cord, y_cord])\n",
    "        x_cord_list.append(x_cord.numpy())\n",
    "        yy.append(y_cord.numpy())\n",
    "\n",
    "    ax.plot(x_cord_list, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "      \n",
    "    ####  Anther loss func ###############################\n",
    "    fig, ax = plot_contour(lambda x, y:  (x)**4 - 10 * (x)** 2 - 3 * (x)+ 40*(y)**2 , name)\n",
    "\n",
    "    x_cord = tf.Variable(-5.0)\n",
    "    y_cord = tf.Variable(-2.0)\n",
    "    x_cord_list = []\n",
    "    yy = []\n",
    "    loss_func = lambda:  x_cord**4 - 10 * x_cord** 2 - 3 * x_cord + 40*y_cord**2 \n",
    "    \n",
    "    for j in range(num_iterations):\n",
    "        step_count = opt.minimize(loss_func, var_list=[x_cord, y_cord])\n",
    "        x_cord_list.append(x_cord.numpy())\n",
    "        yy.append(y_cord.numpy())\n",
    "\n",
    "    ax.plot(x_cord_list, yy, \"o-\")\n",
    "    ax.set_xlabel('Bias')\n",
    "    ax.set_ylabel('Weight')\n",
    "    ax.set_title('Optimization using {name} - Contour Plot'.format(name=name))\n",
    "    \n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     xcoords = np.linspace(-3,3,100)\n",
    "#     ycoord = [loss_func_y(xcoord)  for xcoord in xcoords]\n",
    "#     ax1.plot(xcoords, ycoord)\n",
    "    \n",
    "#     loss_coord = [loss_func_y(y_coord)  for y_coord in yy]\n",
    "#     ax1.plot(yy, loss_coord, 'o-', color='red', alpha=0.6)\n",
    "#     ax1.set_xlabel('Weight')\n",
    "#     ax1.set_ylabel('Loss')\n",
    "#     ax1.set_title('Weight Loss using {name} -  Plot'.format(name=name))                  \n",
    "\n",
    "\n",
    "def run_optimization_static_contour_graph(loss_func_with_args):\n",
    "#     x=loss_func().numpy()\n",
    "#     print(x)\n",
    "#     alpha = 0.0067\n",
    "    optimizers_list = []\n",
    "    optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "    optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 100})\n",
    "    optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 450})\n",
    "    optimizers_list.append({'name': 'adamax', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 450})\n",
    "    \n",
    "    \n",
    "    for optimizer in optimizers_list:\n",
    "        print(optimizer['name'])\n",
    "        opt = optimizer['opt']\n",
    "        plt.clf\n",
    "#         fig1, ax = plot_contour(loss_with_args=loss_func_with_args, title=optimizer['name'])\n",
    "        p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "        p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "        p3, = ax.plot([], [], 'r.')\n",
    "        max_iter = optimizer['max_iter']\n",
    "        do_optimize(loss_with_args=loss_func_with_args, opt=opt, num_iterations=max_iter, name=optimizer['name'])\n",
    "\n",
    "\n",
    "x_cord = tf.Variable(-5.0)\n",
    "y_cord = tf.Variable(-2.0)\n",
    "loss_func = lambda: 1*(x_cord)**2 + 40*(y_cord)**2  \n",
    "\n",
    "# loss_func = lambda: 1*(x_cord)**2 + 40*(y_cord)**2  \n",
    "loss_func_with_args = lambda x_cord, y_cord: 1*(x_cord)**2 + 40*(y_cord)**2        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "run_optimization_static_contour_graph(loss_func_with_args=loss_func_with_args)\n",
    "# out_file_name_prefix = 'loss_diff_gradients_2d_contour_'\n",
    "                                                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e2587",
   "metadata": {},
   "source": [
    "# Scratch static contour with saddle point - fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82dc9b",
   "metadata": {},
   "source": [
    "# scratch 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b75dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #####3D:\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "%matplotlib widget\n",
    "%matplotlib notebook\n",
    "\n",
    "max_iter=100\n",
    "\n",
    "X_COEF=1 #20\n",
    "Y_COEF=40\n",
    "alpha = 0.02517\n",
    "\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "max_iter = 70\n",
    "\n",
    "alpha = 0.0067\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "max_iter= 150\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def f2(x):\n",
    "    return X_COEF*(x[0]+x_offset)**2 + Y_COEF*(x[1]+y_offset)**2\n",
    "\n",
    "def grad2(x):\n",
    "    return np.array([4 * x[0]**3 - 20 * x[0] - 3, 2*Y_COEF*(x[1]+y_offset)])\n",
    "    #return np.array([4 * x**3 - 10 * x - 3, 2*Y_COEF*(x[1]+y_offset)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "v = 0\n",
    "\n",
    "def gd2_momentum_1(x, frame, alpha, grad=grad2, beta=0.9):\n",
    "    global v\n",
    "    v = beta*v + (1-beta)*grad(x)\n",
    "    vc = v/(1+beta**(frame+1))\n",
    "    x = x - alpha * vc\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "rc('animation', html='html5')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "def cost_func(x, y):\n",
    "    Z = (x +x_offset)**4 - 20 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "#     Z = X_COEF*(X+x_offset)**2 + Y_COEF*(Y+y_offset)**2\n",
    "    return Z\n",
    "\n",
    "def plot_loss_func_3d():\n",
    "    x_cord_list = np.linspace(-5.5-x_offset, 5.5-y_offset, 50)\n",
    "    yy = np.linspace(-5.5-x_offset, 5.5-y_offset, 50)\n",
    "    X, Y = np.meshgrid(x_cord_list, yy)\n",
    "    Z = cost_func(X, Y)\n",
    "    fig1 = plt.figure(figsize=(16, 6))\n",
    "    ax1 = fig1.gca(projection='3d')\n",
    "\n",
    "    surf = ax1.plot_surface(X, Y, Z, rstride=1, cstride=1, alpha=0.5, \n",
    "                           linewidth=0, antialiased=False)\n",
    "\n",
    "    ax1.set_xlabel('b', fontsize=20)\n",
    "    ax1.set_ylabel('w1', fontsize=20)\n",
    "    ax1.set_zlabel('J(b, w)', fontsize=20)\n",
    "    ax1.xaxis.set_ticklabels([])\n",
    "    ax1.yaxis.set_ticklabels([])\n",
    "    ax1.zaxis.set_ticklabels([])\n",
    "    plt.show()\n",
    "    return fig1, ax1\n",
    "\n",
    "# plot_loss_func_3d()\n",
    "x = np.linspace(0,5,100)\n",
    "loss = lambda x: 2*x **4 - 20 * x** 2# - 3 * x\n",
    "loss = lambda x: 4.0*tf.cos(x-1)+tf.divide(tf.cos(2.0*np.pi*x),x)\n",
    "y = loss(x)\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8467d823",
   "metadata": {},
   "source": [
    "# Run optimizations - Contour Animation with loss_diff_in_gradients - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ea208",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_diff_in_gradients = lambda: 1*(x_cord)**2 + 40*(y_cord)**2         # d(loss)/d(var1) = var1\n",
    "loss_func = loss_diff_in_gradients\n",
    "loss_with_args = lambda x_cord, y_cord: X_COEF*(x_cord)**2 + Y_COEF*(y_cord)**2         # d(loss)/d(var1) = var1\n",
    "out_file_name_prefix = 'loss_diff_gradients_2d_contour_'\n",
    "\n",
    "optimizers_list = []\n",
    "\n",
    "optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 200})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 200})\n",
    "\n",
    "\n",
    "                   \n",
    "for optimizer in optimizers_list:\n",
    "    print(optimizer['name'])\n",
    "    opt = optimizer['opt']\n",
    "    plt.clf\n",
    "    fig1, ax = plot_contour(loss_with_args=loss_with_args, title=optimizer['name'])\n",
    "    p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "    p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "    p3, = ax.plot([], [], 'r.')\n",
    "    max_iter = optimizer['max_iter']\n",
    "    anim2 = animation.FuncAnimation(fig1, animate_optimizer, init_func=init_animate_optimizer, frames=range(0, max_iter), fargs= (opt, loss_func,), blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "    filename = optimizer['name']+'.gif'\n",
    "    anim2.save('output/'+out_file_name_prefix+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "    anim2.save('output/ronen/Downloads/'+out_file_name_prefix+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "\n",
    "    init_animate_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eba3d1",
   "metadata": {},
   "source": [
    "# Run optimizations - Contout animation with loss local minima - first execute  box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "878b62ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-32e61b77298f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimizers_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moptimizers_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_iter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0moptimizers_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'momentum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_iter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "x_offset=0\n",
    "y_offset=0\n",
    "loss_local_min = lambda:  (x +x_offset)**4 - 10 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "loss_func = loss_local_min\n",
    "out_file_name_prefix = 'loss_local_minima_2d_contour_'\n",
    "loss_with_args = lambda x_cord, y_cord: (x +x_offset)**4 - 10 * (x +x_offset)** 2 - 3 * (x +x_offset)+ Y_COEF*(y+y_offset)**2\n",
    "\n",
    "\n",
    "optimizers_list = []\n",
    "\n",
    "optimizers_list.append({'name': 'sgd', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha), 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'momentum', 'opt': tf.keras.optimizers.SGD(learning_rate=alpha, momentum=0.9), 'max_iter': 100})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adam(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam'), 'max_iter': 200})\n",
    "optimizers_list.append({'name': 'adam', 'opt':  tf.keras.optimizers.Adamax(\n",
    "    learning_rate=alpha, beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
    "    name='Adamax'), 'max_iter': 200})\n",
    "\n",
    "\n",
    "                   \n",
    "for optimizer in optimizers_list:\n",
    "    print(optimizer['name'])\n",
    "    opt = optimizer['opt']\n",
    "    plt.clf\n",
    "    fig1, ax = plot_contour(loss_with_args=loss_with_args, title=optimizer['name'])\n",
    "    p1, = ax.plot([tf.Variable(-5.0)], [tf.Variable(-2.0)], 'kx')\n",
    "    p2, = ax.plot([], [], color='red', alpha=0.6)\n",
    "    p3, = ax.plot([], [], 'r.')\n",
    "    max_iter = optimizer['max_iter']\n",
    "    anim2 = animation.FuncAnimation(fig1, animate_optimizer, init_func=init_animate_optimizer, frames=range(0, max_iter), fargs= (opt, loss_func,), blit=True, interval=50,repeat=True, repeat_delay=20)\n",
    "    filename = optimizer['name']+'.gif'\n",
    "    anim2.save('/home/ronen/Downloads/'+out_file_name_prefix+filename, dpi=80, writer='imagemagick', fps=5)\n",
    "    init_animate_optimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d81c0",
   "metadata": {},
   "source": [
    "# DEmo multi plot animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg') #use Qt5 as backend, comment this line for default backend\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = plt.axes(xlim=(0, 2), ylim=(0, 100))\n",
    "\n",
    "N = 4\n",
    "lines = [plt.plot([], [])[0] for _ in range(N)] #lines to animate\n",
    "\n",
    "rectangles = plt.bar([0.5,1,1.5],[50,40,90],width=0.1) #rectangles to animate\n",
    "\n",
    "patches = lines + list(rectangles) #things to animate\n",
    "\n",
    "def init():\n",
    "    #init lines\n",
    "    for line in lines:\n",
    "        line.set_data([], [])\n",
    "\n",
    "    #init rectangles\n",
    "    for rectangle in rectangles:\n",
    "        rectangle.set_height(0)\n",
    "\n",
    "    return patches #return everything that must be updated\n",
    "\n",
    "def animate(i):\n",
    "    #animate lines\n",
    "    for j,line in enumerate(lines):\n",
    "        line.set_data([0, 2], [10 * j,i])\n",
    "\n",
    "    #animate rectangles\n",
    "    for j,rectangle in enumerate(rectangles):\n",
    "        rectangle.set_height(i/(j+1))\n",
    "\n",
    "    return patches #return everything that must be updated\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=100, interval=20, blit=True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72426af5ec3cce56bef682ad834669827d6f5add9d3dc65518dc2e4de0e7fc82"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
